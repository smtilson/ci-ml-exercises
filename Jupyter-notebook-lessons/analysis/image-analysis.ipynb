{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis - Unit 01- Toy Datasets\n",
    "\n",
    "## Lesson Learning Outcome\n",
    "\n",
    "* **Image Analysis Lesson is made of 3 units**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Evaluate Labels Distribution\n",
    "  * Perform an Image Montage\n",
    "  * Check Average Image and Image Variability\n",
    "  * Check Contrast between 2 average images\n",
    "  * Work with toy and real datasets\n",
    "  * Understand the differences in terms of folder structure when downloading real image datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Unit Objectives\n",
    "\n",
    "* Use a built-in toy dataset and explore: label distribution, deliver an image montage, conduct average image, image variability and contrast between 2 average images studies\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Data Science has incredible applications when dealing with images, either static, like a photo, or dynamic, like a video.\n",
    "\n",
    "\n",
    " **Why do we study Image Analysis?**\n",
    "  * Because it is part of an effective EDA (Exploratory Data Analysis) on images to perform tasks like understanding label distribution, conducting an image montage, compute average image and image variability.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Import Packages for Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Analysis - Toy Dataset \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We haven't studied TensorFlow yet, but we will use TensorFlow toy datasets in this lesson. These are datasets used for learning, meaning they will be useful for understanding the concepts for Image Analysis.\n",
    "* Later in this lesson, we will use real images, where there are additional processes before analyzing the images\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> For now, we will use a dataset called mnist, which is a collection of handwritten numbers from 0 to 9, all in 28 x 28 pixels\n",
    "* We will load the data into a train and test sets\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "Let's check the train and test set size\n",
    "* We will notice the image has only one channel (greyscale). \n",
    "* If it were coloured, it would show (60000, 28, 28, 3) for RGB or (60000, 28, 28, 4) for RGBA\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "As we expect, the data is a NumPy array\n",
    "\n",
    "type(x_train)\n",
    "\n",
    "We are using the function `plt.imshow()` to display a given image. The documentation is found [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html)\n",
    "* We will subset the array using a pointer (num variable). We randomly choose 27\n",
    "* `plt.imshow()` gets the array to be displayed, and, in this case, we set `cmap='gray'` since it is a greyscale image\n",
    "* We can see the number in the image and the respective actual value in the `y_train`\n",
    "\n",
    "pointer = 27\n",
    "\n",
    "print(f\"array pointer = {pointer}\")\n",
    "print(f\"x_train[{pointer}] shape: {x_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(x_train[pointer],cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** play around with `pointer` by setting it to other values. \n",
    "* What is the max value you can use in this case?\n",
    "\n",
    "Also, remove `cmap='gray'` and check the difference. When you don't set this parameter, it will show the default option: `'viridis'`.\n",
    "\n",
    "\n",
    "You can use `set()` to check the unique values in an array. That allows us to understand the labels present in the train set\n",
    "\n",
    "set(y_train)\n",
    "\n",
    "In the cell below, assign a value to a variable named ``pointer``\n",
    "* Use plt.imshow, x_train, pointer, and cmap\n",
    "* Show plt\n",
    "\n",
    "# Write your code here.\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Labels Distribution\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use the convention **`label`**, as the levels or classes in a image dataset.\n",
    "* For example, in mnist dataset, the labels are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
    "\n",
    "We are interested in knowing if the target variable is balanced and understanding if the labels have similar frequency levels.\n",
    "* We assess that with `.value_counts()` and a bar plot.\n",
    "* We first convert the y_train array to a Pandas Series, then count the values, sort the index and plot with Pandas\n",
    "* We notice the labels are fairly distributed.\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.Series(data=y_train).value_counts().sort_index().plot(kind='bar',figsize=(12,5))\n",
    "plt.title(\"Train Set: Labels Distribution\")\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Montage\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> An Image Montage aims to display a grid of images per label\n",
    "* We created a custom function for this task. We will not describe the specifics of the function. The function was made using the knowledge covered in the course and functionalities for creating a list with indices pair to plot in the image grid and randomly subset several images to be displayed\n",
    "\n",
    "* The function arguments are: \n",
    "  * `X`: NumPy array with image data, \n",
    "  * `y`: NumPy array with target value, label_to_display, \n",
    "  * `nrows` and `ncols` to define the grid structure and \n",
    "  * `figsize`.\n",
    "\n",
    "\n",
    "Read the pseudo code to understand the function capabilities better\n",
    "  * It is resonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "def image_montage_data_as_array(X, y,label_to_display, nrows, ncols, figsize=(15,10)):\n",
    "  \"\"\"\n",
    "   The pseudo code for the function is:\n",
    "  * Subset the label you are interested\n",
    "  * If the label is not in the target array, shows montage with all labels\n",
    "  * Check if your grid space is greater than the subset (nrows x ncols) size\n",
    "  * Create list of axes indices based on nrows and ncols\n",
    "  * Create a Figure and display images\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  # subset the label you are interested in displaying\n",
    "  if label_to_display in np.unique(y):\n",
    "    y = y.reshape(-1,1,1)\n",
    "    boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "    df = X[boolean_mask]\n",
    "\n",
    "  # if that label is not in the data, it shows a montage with all labels\n",
    "  else:\n",
    "    print(\"The class you selected doesn't exist.\")\n",
    "    print(f\"The existing options are: {np.unique(y)}\")\n",
    "    print(\"Find below a montage with all labels\")\n",
    "    df = X\n",
    "\n",
    "  # checks if your montage space is greater than subset size\n",
    "  if nrows * ncols < df.shape[0]:\n",
    "    img_idx = random.sample(range(0, df.shape[0]), nrows * ncols)\n",
    "  else:\n",
    "    print(\n",
    "        f\"Decrease nrows or ncols to create your montage. \\n\"\n",
    "        f\"There are {df.shape[0]} in your subset. \"\n",
    "        f\"You requested a montage with {nrows * ncols} spaces\")\n",
    "    return\n",
    "    \n",
    "  # create list of axes indices based on nrows and ncols\n",
    "  list_rows= range(0,nrows)\n",
    "  list_cols= range(0,ncols)\n",
    "  plot_idx = list(itertools.product(list_rows,list_cols))\n",
    "\n",
    "  # create a Figure and display images\n",
    "  fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=figsize)\n",
    "  for x in range(0,nrows*ncols):\n",
    "    axes[plot_idx[x][0], plot_idx[x][1]].imshow(df[img_idx[x]], cmap='gray')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's display the label 8, in a 3 x 5 grid.\n",
    "* Note how different the number 8 can be written!\n",
    "\n",
    "image_montage_data_as_array(X=x_train, y=y_train,\n",
    "              label_to_display=8,\n",
    "              nrows=3, ncols=5,\n",
    "              figsize=(15,10))\n",
    "\n",
    "Do an exercise and change the label value \n",
    "\n",
    "image_montage_data_as_array(X=x_train, y=y_train,\n",
    "              label_to_display=9,\n",
    "              nrows=3, ncols=5,\n",
    "              figsize=(15,10))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** We will use another builtin dataset from TensorFlow\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_practice, y_practice), (x_practice_test, y_practice_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "Label\tDescription\n",
    "* 0\tT-shirt/top\n",
    "* 1\tTrouser\n",
    "* 2\tPullover\n",
    "* 3\tDress\n",
    "* 4\tCoat\n",
    "* 5\tSandal\n",
    "* 6\tShirt\n",
    "* 7\tSneaker\n",
    "* 8\tBag\n",
    "* 9\tAnkle boot\n",
    "\n",
    "Use your existing knowledge to asses the label distribution\n",
    "\n",
    "# write the code here to assess label distribution\n",
    "\n",
    "\n",
    "In the following cell, call the ``image_montage_data_as_array`` custom function to make an image montage\n",
    "* choose a label from 0-9 \n",
    "\n",
    "# Write your code here.\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Average Image and Image Variability per Label\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We noticed that for each label, the images would be slightly different from each other, but in general, we expect them to have a pattern\n",
    "\n",
    "An Average Image and Image Variability per label helps to study these patterns\n",
    "* An average image is when you subset all data (NumPy arrays) from a given label and calculate the average from the array values\n",
    "* Image Variability is when you subset all data (NumPy arrays) from a given label and calculate the standard deviation from the array values\n",
    "\n",
    "\n",
    "Read the pseudo-code to understand the function capabilities better\n",
    "  * It is reasonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "\n",
    "def image_avg_and_variability_data_as_array(X, y, figsize=(12,5)):\n",
    "  \"\"\"\n",
    "   The pseudo-code for the function is:\n",
    "  * Loop through all labels\n",
    "  * Subset an array for a given label\n",
    "  * Calculate the average and standard deviation\n",
    "  * Create a Figure displaying the average and variability image\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  for label_to_display in np.unique(y):\n",
    "\n",
    "    y = y.reshape(-1,1,1)\n",
    "    boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "    arr = X[boolean_mask]\n",
    "\n",
    "    avg_img = np.mean(arr, axis = 0)\n",
    "    std_img = np.std(arr, axis = 0)\n",
    "    print(f\"==== Label {label_to_display} ====\")\n",
    "    print(f\"Image Shape: {avg_img.shape}\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
    "    axes[0].set_title(f\"Average Image for label {label_to_display}\")\n",
    "    axes[0].imshow(avg_img, cmap='gray')\n",
    "    axes[1].set_title(f\"Image Variability for label {label_to_display}\")\n",
    "    axes[1].imshow(std_img, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help with the interpretation, consider the following guide:\n",
    "* Check for the patterns where the colour is darker or lighter\n",
    "* For **Average Image**, we notice the general patterns for a given label\n",
    "* For **Image Variability**, the lighter area indicates higher variability in that area. For example, for zero, we see the middle is black (meaning all zeros tend not to have the middle filled), and a circled area is white (meaning the images tend to vary in this circled area)\n",
    "* You will notice that the plots complement each other since both, from different angles, show the image patterns\n",
    "\n",
    "\n",
    "\n",
    "image_avg_and_variability_data_as_array(X=x_train, y=y_train, figsize=(12,5))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note: There will be datasets where the images in a given label will have distinct shapes or patterns, and an average and variability study may not give the same amount of insights as we see in the mnist dataset\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> For example, your dataset may contain images of fish and birds from multiple species. \n",
    "* Eventually, when you subset fishes and calculate an average image, the result will be a combination of patterns from multiple fish species that may confuse a user unfamiliar with the context.\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Contrast between 2 Labels\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Here we are interested in evaluating the contrast between the two labels.\n",
    "* Which may provide additional insight into how the labels differ from each other\n",
    "\n",
    "* We created a custom function contrast_between_2_labels_data_as_array() that computes that. The arguments are `X`, for the image data in NumPy array, `y` as the array indicating the label; `label_1` and `label_2` as the labels you are interested in compairing and `figsize` to set figure size\n",
    "\n",
    "  * It is reasonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "def subset_image_label(X,y,label_to_display):\n",
    "  y = y.reshape(-1,1,1)\n",
    "  boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "  df = X[boolean_mask]\n",
    "  return df\n",
    "\n",
    "def contrast_between_2_labels_data_as_array(X, y, label_1, label_2, figsize=(12,5)):\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  if (label_1 not in np.unique(y)) or (label_2 not in np.unique(y)):\n",
    "    print(f\"Either label {label} or label {label_2}, are not in {np.unique(y)} \")\n",
    "    return\n",
    "\n",
    "  # calculate mean from label1\n",
    "  images_label = subset_image_label(X, y, label_1)\n",
    "  label1_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate mean from label2\n",
    "  images_label = subset_image_label(X, y, label_2)\n",
    "  label2_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate difference and plot difference, avg label1 and avg label2\n",
    "  contrast_mean = label1_avg - label2_avg\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
    "  axes[0].imshow(contrast_mean, cmap='gray')\n",
    "  axes[0].set_title(f'Difference Between Averages: {label_1} & {label_2}')\n",
    "  axes[1].imshow(label1_avg, cmap='gray')\n",
    "  axes[1].set_title(f'Average {label_1}')\n",
    "  axes[2].imshow(label2_avg, cmap='gray')\n",
    "  axes[2].set_title(f'Average {label_2}')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help the interpretation, consider the following guide:\n",
    "* You are comparing label_1 to label_2\n",
    "* In the Difference Between Averages plot, the darker area shows where both average images are similar. The lighter area shows where average images are different\n",
    "\n",
    "contrast_between_2_labels_data_as_array(X=x_train, y=y_train,\n",
    "                                        label_1=8, label_2=2,\n",
    "                                        figsize=(12,10)\n",
    "                                        )\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The same note from the previous section applies here:\n",
    "* There will be datasets where the images in a given label will have distinct shapes or patterns, and contrast from averages study may not provide the same amount of insights as we see in mnist dataset\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** Use your existing knowledge to assess the \n",
    "* average image, image variability per label, \n",
    "* and contrast between labels for x_practice and y_practice data\n",
    "\n",
    "# write the code here to assess average image, image variability\n",
    "\n",
    "\n",
    "# write the code here for the contrast between 2 labels \n",
    "# We suggest you to try with a few pairs of labels so that you can get comfortable with the data \n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
