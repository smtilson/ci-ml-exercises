{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis - Unit 01- Toy Datasets\n",
    "\n",
    "## Lesson Learning Outcome\n",
    "\n",
    "* **Image Analysis Lesson is made of 3 units**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Evaluate Labels Distribution\n",
    "  * Perform an Image Montage\n",
    "  * Check Average Image and Image Variability\n",
    "  * Check Contrast between 2 average images\n",
    "  * Work with toy and real datasets\n",
    "  * Understand the differences in terms of folder structure when downloading real image datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Unit Objectives\n",
    "\n",
    "* Use a built-in toy dataset and explore: label distribution, deliver an image montage, conduct average image, image variability and contrast between 2 average images studies\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Data Science has incredible applications when dealing with images, either static, like a photo, or dynamic, like a video.\n",
    "\n",
    "\n",
    " **Why do we study Image Analysis?**\n",
    "  * Because it is part of an effective EDA (Exploratory Data Analysis) on images to perform tasks like understanding label distribution, conducting an image montage, compute average image and image variability.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Import Packages for Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Image Analysis - Toy Dataset \n",
    "\n",
    "\n",
    "* We haven't studied TensorFlow yet, but we will use TensorFlow toy datasets in this lesson. These are datasets used for learning, meaning they will be useful for understanding the concepts for Image Analysis.\n",
    "* Later in this lesson, we will use real images, where there are additional processes before analyzing the images\n",
    "\n",
    "\n",
    "* For now, we will use a dataset called mnist, which is a collection of handwritten numbers from 0 to 9, all in 28 x 28 pixels\n",
    "* We will load the data into a train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 10:35:53.467374: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 10:35:53.492732: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-08 10:35:53.562093: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-08 10:35:53.562903: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x7fbe87675ac0> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[1;32m      3\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/tensorflow/python/eager/context.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n",
      "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tf_session\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tf_session\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _TF_SetTarget\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tf_session\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _TF_SetConfig\n",
      "\u001b[0;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's check the train and test set size\n",
    "* We will notice the image has only one channel (greyscale). \n",
    "* If it were coloured, it would show (60000, 28, 28, 3) for RGB or (60000, 28, 28, 4) for RGBA\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "As we expect, the data is a NumPy array\n",
    "\n",
    "type(x_train)\n",
    "\n",
    "We are using the function `plt.imshow()` to display a given image. The documentation is found [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html)\n",
    "* We will subset the array using a pointer (num variable). We randomly choose 27\n",
    "* `plt.imshow()` gets the array to be displayed, and, in this case, we set `cmap='gray'` since it is a greyscale image\n",
    "* We can see the number in the image and the respective actual value in the `y_train`\n",
    "\n",
    "pointer = 27\n",
    "\n",
    "print(f\"array pointer = {pointer}\")\n",
    "print(f\"x_train[{pointer}] shape: {x_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(x_train[pointer],cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** play around with `pointer` by setting it to other values. \n",
    "* What is the max value you can use in this case?\n",
    "\n",
    "Also, remove `cmap='gray'` and check the difference. When you don't set this parameter, it will show the default option: `'viridis'`.\n",
    "\n",
    "\n",
    "You can use `set()` to check the unique values in an array. That allows us to understand the labels present in the train set\n",
    "\n",
    "set(y_train)\n",
    "\n",
    "In the cell below, assign a value to a variable named ``pointer``\n",
    "* Use plt.imshow, x_train, pointer, and cmap\n",
    "* Show plt\n",
    "\n",
    "# Write your code here.\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Labels Distribution\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use the convention **`label`**, as the levels or classes in a image dataset.\n",
    "* For example, in mnist dataset, the labels are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
    "\n",
    "We are interested in knowing if the target variable is balanced and understanding if the labels have similar frequency levels.\n",
    "* We assess that with `.value_counts()` and a bar plot.\n",
    "* We first convert the y_train array to a Pandas Series, then count the values, sort the index and plot with Pandas\n",
    "* We notice the labels are fairly distributed.\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.Series(data=y_train).value_counts().sort_index().plot(kind='bar',figsize=(12,5))\n",
    "plt.title(\"Train Set: Labels Distribution\")\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Montage\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> An Image Montage aims to display a grid of images per label\n",
    "* We created a custom function for this task. We will not describe the specifics of the function. The function was made using the knowledge covered in the course and functionalities for creating a list with indices pair to plot in the image grid and randomly subset several images to be displayed\n",
    "\n",
    "* The function arguments are: \n",
    "  * `X`: NumPy array with image data, \n",
    "  * `y`: NumPy array with target value, label_to_display, \n",
    "  * `nrows` and `ncols` to define the grid structure and \n",
    "  * `figsize`.\n",
    "\n",
    "\n",
    "Read the pseudo code to understand the function capabilities better\n",
    "  * It is resonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "def image_montage_data_as_array(X, y,label_to_display, nrows, ncols, figsize=(15,10)):\n",
    "  \"\"\"\n",
    "   The pseudo code for the function is:\n",
    "  * Subset the label you are interested\n",
    "  * If the label is not in the target array, shows montage with all labels\n",
    "  * Check if your grid space is greater than the subset (nrows x ncols) size\n",
    "  * Create list of axes indices based on nrows and ncols\n",
    "  * Create a Figure and display images\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  # subset the label you are interested in displaying\n",
    "  if label_to_display in np.unique(y):\n",
    "    y = y.reshape(-1,1,1)\n",
    "    boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "    df = X[boolean_mask]\n",
    "\n",
    "  # if that label is not in the data, it shows a montage with all labels\n",
    "  else:\n",
    "    print(\"The class you selected doesn't exist.\")\n",
    "    print(f\"The existing options are: {np.unique(y)}\")\n",
    "    print(\"Find below a montage with all labels\")\n",
    "    df = X\n",
    "\n",
    "  # checks if your montage space is greater than subset size\n",
    "  if nrows * ncols < df.shape[0]:\n",
    "    img_idx = random.sample(range(0, df.shape[0]), nrows * ncols)\n",
    "  else:\n",
    "    print(\n",
    "        f\"Decrease nrows or ncols to create your montage. \\n\"\n",
    "        f\"There are {df.shape[0]} in your subset. \"\n",
    "        f\"You requested a montage with {nrows * ncols} spaces\")\n",
    "    return\n",
    "    \n",
    "  # create list of axes indices based on nrows and ncols\n",
    "  list_rows= range(0,nrows)\n",
    "  list_cols= range(0,ncols)\n",
    "  plot_idx = list(itertools.product(list_rows,list_cols))\n",
    "\n",
    "  # create a Figure and display images\n",
    "  fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=figsize)\n",
    "  for x in range(0,nrows*ncols):\n",
    "    axes[plot_idx[x][0], plot_idx[x][1]].imshow(df[img_idx[x]], cmap='gray')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's display the label 8, in a 3 x 5 grid.\n",
    "* Note how different the number 8 can be written!\n",
    "\n",
    "image_montage_data_as_array(X=x_train, y=y_train,\n",
    "              label_to_display=8,\n",
    "              nrows=3, ncols=5,\n",
    "              figsize=(15,10))\n",
    "\n",
    "Do an exercise and change the label value \n",
    "\n",
    "image_montage_data_as_array(X=x_train, y=y_train,\n",
    "              label_to_display=9,\n",
    "              nrows=3, ncols=5,\n",
    "              figsize=(15,10))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** We will use another builtin dataset from TensorFlow\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_practice, y_practice), (x_practice_test, y_practice_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "Label\tDescription\n",
    "* 0\tT-shirt/top\n",
    "* 1\tTrouser\n",
    "* 2\tPullover\n",
    "* 3\tDress\n",
    "* 4\tCoat\n",
    "* 5\tSandal\n",
    "* 6\tShirt\n",
    "* 7\tSneaker\n",
    "* 8\tBag\n",
    "* 9\tAnkle boot\n",
    "\n",
    "Use your existing knowledge to asses the label distribution\n",
    "\n",
    "# write the code here to assess label distribution\n",
    "\n",
    "\n",
    "In the following cell, call the ``image_montage_data_as_array`` custom function to make an image montage\n",
    "* choose a label from 0-9 \n",
    "\n",
    "# Write your code here.\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Average Image and Image Variability per Label\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We noticed that for each label, the images would be slightly different from each other, but in general, we expect them to have a pattern\n",
    "\n",
    "An Average Image and Image Variability per label helps to study these patterns\n",
    "* An average image is when you subset all data (NumPy arrays) from a given label and calculate the average from the array values\n",
    "* Image Variability is when you subset all data (NumPy arrays) from a given label and calculate the standard deviation from the array values\n",
    "\n",
    "\n",
    "Read the pseudo-code to understand the function capabilities better\n",
    "  * It is reasonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "\n",
    "def image_avg_and_variability_data_as_array(X, y, figsize=(12,5)):\n",
    "  \"\"\"\n",
    "   The pseudo-code for the function is:\n",
    "  * Loop through all labels\n",
    "  * Subset an array for a given label\n",
    "  * Calculate the average and standard deviation\n",
    "  * Create a Figure displaying the average and variability image\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  for label_to_display in np.unique(y):\n",
    "\n",
    "    y = y.reshape(-1,1,1)\n",
    "    boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "    arr = X[boolean_mask]\n",
    "\n",
    "    avg_img = np.mean(arr, axis = 0)\n",
    "    std_img = np.std(arr, axis = 0)\n",
    "    print(f\"==== Label {label_to_display} ====\")\n",
    "    print(f\"Image Shape: {avg_img.shape}\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
    "    axes[0].set_title(f\"Average Image for label {label_to_display}\")\n",
    "    axes[0].imshow(avg_img, cmap='gray')\n",
    "    axes[1].set_title(f\"Image Variability for label {label_to_display}\")\n",
    "    axes[1].imshow(std_img, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help with the interpretation, consider the following guide:\n",
    "* Check for the patterns where the colour is darker or lighter\n",
    "* For **Average Image**, we notice the general patterns for a given label\n",
    "* For **Image Variability**, the lighter area indicates higher variability in that area. For example, for zero, we see the middle is black (meaning all zeros tend not to have the middle filled), and a circled area is white (meaning the images tend to vary in this circled area)\n",
    "* You will notice that the plots complement each other since both, from different angles, show the image patterns\n",
    "\n",
    "\n",
    "\n",
    "image_avg_and_variability_data_as_array(X=x_train, y=y_train, figsize=(12,5))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note: There will be datasets where the images in a given label will have distinct shapes or patterns, and an average and variability study may not give the same amount of insights as we see in the mnist dataset\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> For example, your dataset may contain images of fish and birds from multiple species. \n",
    "* Eventually, when you subset fishes and calculate an average image, the result will be a combination of patterns from multiple fish species that may confuse a user unfamiliar with the context.\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Contrast between 2 Labels\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Here we are interested in evaluating the contrast between the two labels.\n",
    "* Which may provide additional insight into how the labels differ from each other\n",
    "\n",
    "* We created a custom function contrast_between_2_labels_data_as_array() that computes that. The arguments are `X`, for the image data in NumPy array, `y` as the array indicating the label; `label_1` and `label_2` as the labels you are interested in compairing and `figsize` to set figure size\n",
    "\n",
    "  * It is reasonable if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "def subset_image_label(X,y,label_to_display):\n",
    "  y = y.reshape(-1,1,1)\n",
    "  boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "  df = X[boolean_mask]\n",
    "  return df\n",
    "\n",
    "def contrast_between_2_labels_data_as_array(X, y, label_1, label_2, figsize=(12,5)):\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  if (label_1 not in np.unique(y)) or (label_2 not in np.unique(y)):\n",
    "    print(f\"Either label {label} or label {label_2}, are not in {np.unique(y)} \")\n",
    "    return\n",
    "\n",
    "  # calculate mean from label1\n",
    "  images_label = subset_image_label(X, y, label_1)\n",
    "  label1_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate mean from label2\n",
    "  images_label = subset_image_label(X, y, label_2)\n",
    "  label2_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate difference and plot difference, avg label1 and avg label2\n",
    "  contrast_mean = label1_avg - label2_avg\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
    "  axes[0].imshow(contrast_mean, cmap='gray')\n",
    "  axes[0].set_title(f'Difference Between Averages: {label_1} & {label_2}')\n",
    "  axes[1].imshow(label1_avg, cmap='gray')\n",
    "  axes[1].set_title(f'Average {label_1}')\n",
    "  axes[2].imshow(label2_avg, cmap='gray')\n",
    "  axes[2].set_title(f'Average {label_2}')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help the interpretation, consider the following guide:\n",
    "* You are comparing label_1 to label_2\n",
    "* In the Difference Between Averages plot, the darker area shows where both average images are similar. The lighter area shows where average images are different\n",
    "\n",
    "contrast_between_2_labels_data_as_array(X=x_train, y=y_train,\n",
    "                                        label_1=8, label_2=2,\n",
    "                                        figsize=(12,10)\n",
    "                                        )\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The same note from the previous section applies here:\n",
    "* There will be datasets where the images in a given label will have distinct shapes or patterns, and contrast from averages study may not provide the same amount of insights as we see in mnist dataset\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE** Use your existing knowledge to assess the \n",
    "* average image, image variability per label, \n",
    "* and contrast between labels for x_practice and y_practice data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write the code here to assess average image, image variability\n",
    "\n",
    "\n",
    "# write the code here for the contrast between 2 labels \n",
    "# We suggest you to try with a few pairs of labels so that you can get comfortable with the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis - Unit 02 - Real Datasets - Part 01\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Use a real dataset and explore: label distribution, deliver an image montage, conduct average image, image variability and contrast between 2 average images studies\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Lets extract the image files we will be using\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('Chess.zip', 'r') as chessZip:\n",
    "   chessZip.extractall()\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Analysis - Real Datasets - Part 01\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Real image datasets are different from the toy datasets we find in the ML libraries\n",
    "* One major difference is the fact that real images will likely have different sizes; for example, you can't expect all images to be in the 100 x 50 pixels format.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> One possible approach is that downloaded images will be arranged in a folder. Each folder will contain a set of sub-folders related to the image labels. In each sub-folder, we find the image files\n",
    "* Ultimately we want to have three folders: Train, Validation and Test. However, your dataset may come with: \n",
    "  * One folder (with subfolders as the labels)\n",
    "  * Two folders (like Train and Test)\n",
    "  * Or three folders (with Train, Validation and Test)\n",
    "\n",
    "* Let's imagine our dataset is called Animals_Image, and there are three labels: Dog, Cat and Parrot. The data could be in one of three formats below:\n",
    "  * Imagine there aren't only two distinct images in each folder. Instead, there is a set of images for each label or in each folder\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We want our data to be in a 3-folder structure. We will need to move files between folders and do that programmatically. We will cover how to do that in the next unit.\n",
    "\n",
    "* In this unit, we will use a dataset that comes with one folder only.\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Analysis\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use the following workflow to start our image analysis study in this unit:\n",
    "* 1 - Set data directory\n",
    "* 2 - Delete non-image files\n",
    "* 3 -  Assess Labels Distribution\n",
    "* 4 - Build an Image Montage\n",
    "* 5 - Calculate Average Image and Image Variability\n",
    "* 6 - Contrast Between 2 Labels\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Set Data Directory\n",
    "\n",
    "You will locate your data directory\n",
    "* That is the root path of your data. In this case, the sub-folder option is the dataset name folder: Chess\n",
    "\n",
    "my_data_dir = 'Chess'\n",
    "my_data_dir\n",
    "\n",
    "The labels are assessed based on the folder names in the Chess folder. This is done with the command: `os.listdir()`, where the argument is: `'Chess'`. The documentation is found [here](https://docs.python.org/3/library/os.html#os.listdir)\n",
    "\n",
    "import os\n",
    "labels = os.listdir(my_data_dir)\n",
    "labels\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Labels Distribution\n",
    "\n",
    "We create custom code that:\n",
    "* Stores in a DataFrame: the name of the set (in this case, Chess), the label and its frequency\n",
    "* We plot the DataFrame in a barplot showing the frequencies.\n",
    "\n",
    "df_freq = pd.DataFrame([]) \n",
    "for folder in ['Chess']:   \n",
    "                  # think 'Chess' as a Set Folder. \n",
    "                  # Ideally we want a Train Set, Val Set and Test Set\n",
    "  for label in labels:\n",
    "    df_freq = df_freq.append(\n",
    "        pd.Series(data={'Set': folder,\n",
    "                        'Label': label,\n",
    "                        'Frequency':len(os.listdir(folder + '/' + label))}\n",
    "                  ),\n",
    "                  ignore_index=True\n",
    "        )\n",
    "    \n",
    "\n",
    "df_freq\n",
    "\n",
    "We plot the DataFrame using a barplot, where x is the `Set` (in this case is only Chess), y is the `Frequency`, and hue is `Label`\n",
    "* We notice the label's frequencies are not the same across all labels. There are sections where one is much less than another \n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.show()\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Montage\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Similarly to the previous unit, we want to do an Image Montage on the labels to start understanding the dataset\n",
    "* The difference is that the dataset is located in folders, not in an array. One key logic difference of this function is that it loops through the image names across different folders and \"load and plot\" the images in a Figure\n",
    "* Check the pseudo code to understand the logic\n",
    "  * It is normal and okay if you don't at first understand all code in the function below. The central point is making sense of the pseudo-code and understanding the function parameters\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "\n",
    "\n",
    "def image_montage(dir_path, label_to_display, nrows, ncols, figsize=(15,10)):\n",
    "  \"\"\"\n",
    "  logic\n",
    "  - if a label exists in the folder\n",
    "  - check if your montage space is greater than nsubset size\n",
    "  - create a list of axes indices based on nrows and ncols\n",
    "  - create a Figure and display images\n",
    "  - in this loop, load the image and plot the given image\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  labels = os.listdir(dir_path)\n",
    "\n",
    "  # subset the class you are interested in displaying\n",
    "  if label_to_display in labels:\n",
    "\n",
    "    # checks if your montage space is greater than subset size\n",
    "    images_list = os.listdir(dir_path+'/'+ label_to_display)\n",
    "    if nrows * ncols < len(images_list):\n",
    "      img_idx = random.sample(images_list, nrows * ncols)\n",
    "    else:\n",
    "      print(\n",
    "          f\"Decrease nrows or ncols to create your montage. \\n\"\n",
    "          f\"There are {len(images_list)} in your subset. \"\n",
    "          f\"You requested a montage with {nrows * ncols} spaces\")\n",
    "      return\n",
    "    \n",
    "\n",
    "    # create a list of axes indices based on nrows and ncols\n",
    "    list_rows= range(0,nrows)\n",
    "    list_cols= range(0,ncols)\n",
    "    plot_idx = list(itertools.product(list_rows,list_cols))\n",
    "\n",
    "\n",
    "    # create a Figure and display images\n",
    "    fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=figsize)\n",
    "    for x in range(0,nrows*ncols):\n",
    "      img = imread(dir_path + '/' + label_to_display + '/' + img_idx[x], 0)\n",
    "      img_shape = img.shape\n",
    "      axes[plot_idx[x][0], plot_idx[x][1]].imshow(img)\n",
    "      axes[plot_idx[x][0], plot_idx[x][1]].set_title(f\"Width {img_shape[1]}px x Height {img_shape[0]}px\")\n",
    "      axes[plot_idx[x][0], plot_idx[x][1]].set_xticks([])\n",
    "      axes[plot_idx[x][0], plot_idx[x][1]].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  else:\n",
    "    print(\"The label you selected doesn't exist.\")\n",
    "    print(f\"The existing options are: {labels}\")\n",
    "\n",
    "We create the logic where we loop over the labels, and for each, we do an image montage\n",
    "* Note also the dimension of the images are different\n",
    "\n",
    "for label in labels:\n",
    "  print(label)\n",
    "  image_montage(dir_path= my_data_dir,\n",
    "                label_to_display= label,\n",
    "                nrows=2, ncols=3,\n",
    "                figsize=(10,15)\n",
    "                )\n",
    "  print(\"\\n\")\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Average Image and Image Variability per Label\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  All images must be the same size to compute an average image. First, we need to determine what will be the average image size so that we can load all images in a uniform array\n",
    "* We loop over the `train_path`, load each image and store the height and width in `dim1` and `dim2`. After, we plot the size of the images in a scatterplot and indicate the average image value for width and height\n",
    "\n",
    "dim1, dim2 = [], []\n",
    "for label in labels:\n",
    "  for image_filename in os.listdir(my_data_dir + '/'+ label):\n",
    "    img = imread(my_data_dir + '/' + label + '/'+ image_filename, 0)\n",
    "    img_shape = img.shape\n",
    "    dim1.append(img_shape[0]) # image height\n",
    "    dim2.append(img_shape[1]) # image width\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots()\n",
    "sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
    "axes.set_xlabel(\"Width (pixels)\")\n",
    "axes.set_ylabel(\"Height (pixels)\")\n",
    "dim1_mean = int(np.array(dim1).mean())\n",
    "dim2_mean = int(np.array(dim2).mean())\n",
    "axes.axvline(x=dim2_mean,color='r', linestyle='--')\n",
    "axes.axhline(y=dim1_mean,color='r', linestyle='--')\n",
    "plt.show()\n",
    "print(f\"Width average: {dim2_mean} \\nHeight average: {dim1_mean}\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We need to load all images into a uniform array.\n",
    "* We create a custom function that loops over a directory. In this directory, we find the possible labels as sub-folder. For each label (sub-folder), we load the image, resize to the average width and height we computed earlier and store it in an array. \n",
    "* In the end we have X and y arrays, where X stores the image pixels and y labels for each image.\n",
    "  * It is normal and okay if you don't at first understand all code in the function below. The central point is to make sense of the function parameters.\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_image_as_array(my_data_dir, new_size=(50,50), images_amount = 20):\n",
    "  \n",
    "  X, y = np.array([], dtype='int'), np.array([], dtype='object')\n",
    "  labels = os.listdir(my_data_dir)\n",
    "\n",
    "  for label in labels:\n",
    "    counter = 0\n",
    "    for image_filename in os.listdir(my_data_dir + '/' + label):\n",
    "      if counter < images_amount:\n",
    "        \n",
    "        img = image.load_img(my_data_dir + '/' + label + '/' + image_filename, target_size=new_size)\n",
    "        if image.img_to_array(img).max() > 1: \n",
    "          img_resized = image.img_to_array(img) / 255\n",
    "        else: \n",
    "          img_resized = image.img_to_array(img)\n",
    "        \n",
    "        X = np.append(X, img_resized).reshape(-1, new_size[0], new_size[1], img_resized.shape[2])\n",
    "        y = np.append(y, label)\n",
    "        counter += 1\n",
    "\n",
    "  return X, y\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The function parameters are:\n",
    "* `my_data_dir`, we provide train_path (`/content/chess_dataset/Chessman-image-dataset/Chess`),\n",
    "* `new_size`, which is the average image dimension from this dataset, and \n",
    "* `images_amount`, which is the number of images per label you want to load. You should consider that loading, resizing and storing image data will have a considerable computing cost. Here we can load the same amount of images per label and set a value that will not take much time to load. Also you may have memory issues when loading a lot of images, depending on your memory availability\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> It may take 2 or 3 minutes to load all images\n",
    "\n",
    "X, y = load_image_as_array(my_data_dir=my_data_dir,\n",
    "                           new_size=(dim1_mean,dim2_mean),\n",
    "                           images_amount = 2)\n",
    "\n",
    "We will use `image_avg_and_variability_data_as_array()` to understand the average image and image variability for this dataset. This is the same function we used in the last unit\n",
    "\n",
    "def image_avg_and_variability_data_as_array(X, y, figsize=(12,5)):\n",
    "  \"\"\"\n",
    "   The pseudo-code for the function is:\n",
    "  * Loop through all labels\n",
    "  * Subset an array for a given label\n",
    "  * Calculate the average and standard deviation\n",
    "  * Create a Figure displaying the average and variability image\n",
    "\n",
    "  \"\"\"\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  for label_to_display in np.unique(y):\n",
    "\n",
    "    y = y.reshape(-1,1,1)\n",
    "    boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "    arr = X[boolean_mask]\n",
    "\n",
    "    avg_img = np.mean(arr, axis = 0)\n",
    "    std_img = np.std(arr, axis = 0)\n",
    "    print(f\"==== Label {label_to_display} ====\")\n",
    "    print(f\"Image Shape: {avg_img.shape}\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
    "    axes[0].set_title(f\"Average Image for label {label_to_display}\")\n",
    "    axes[0].imshow(avg_img, cmap='gray')\n",
    "    axes[1].set_title(f\"Image Variability for label {label_to_display}\")\n",
    "    axes[1].imshow(std_img, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "  \n",
    "\n",
    "We parse X and y to understand average image and image variability per label\n",
    "* You will likely notice typical patterns/shapes for pieces like king or knight; However, the images (average and variability) may be too blurred. \n",
    "* This happens since we didn't load many images since we just wanted to show the use case. In case you want, get back to `load_image_as_array()`, set a higher value `images_amount`,  and rerun `image_avg_and_variability_data_as_array()`\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help the interpretation, consider the following guide:\n",
    "* Check for the patterns where the colour is darker or lighter\n",
    "* For **Average Image**, we notice the general patterns for a given label\n",
    "* For **Image Variability**, the lighter area indicates higher variability across images from the same label in that area. \n",
    "\n",
    "image_avg_and_variability_data_as_array(X=X, y=y, figsize=(12,5))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note: There will be datasets where the images in a given label will have distinct shapes or patterns, and an average and variability study may not give the same amount of insights as we see in mnist dataset\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> For example, your dataset may contain images of fish and birds from multiple species. \n",
    "* Eventually, when you subset fishes and calculate an average image, the result will be a combination of patterns from multiple fish species that may confuse a user unfamiliar with the context.\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Contrast between 2 Labels\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We may be at a point in our project where we want to know the differences between 2 classes\n",
    "* We will use the same function from last unit `contrast_between_2_labels_data_as_array()`\n",
    "\n",
    "def subset_image_label(X,y,label_to_display):\n",
    "  y = y.reshape(-1,1,1)\n",
    "  boolean_mask = np.any(y==label_to_display,axis=1).reshape(-1)\n",
    "  df = X[boolean_mask]\n",
    "  return df\n",
    "\n",
    "def contrast_between_2_labels_data_as_array(X, y, label_1, label_2, figsize=(12,5)):\n",
    "  sns.set_style(\"white\")\n",
    "\n",
    "  if (label_1 not in np.unique(y)) or (label_2 not in np.unique(y)):\n",
    "    print(f\"Either label {label} or label {label_2}, are not in {np.unique(y)} \")\n",
    "    return\n",
    "\n",
    "  # calculate the mean from label1\n",
    "  images_label = subset_image_label(X, y, label_1)\n",
    "  label1_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate the mean from label2\n",
    "  images_label = subset_image_label(X, y, label_2)\n",
    "  label2_avg = np.mean(images_label, axis = 0)\n",
    "\n",
    "  # calculate the difference and plot the difference, avg label1 and avg label2\n",
    "  contrast_mean = label1_avg - label2_avg\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
    "  axes[0].imshow(contrast_mean, cmap='gray')\n",
    "  axes[0].set_title(f'Difference Between Averages: {label_1} & {label_2}')\n",
    "  axes[1].imshow(label1_avg, cmap='gray')\n",
    "  axes[1].set_title(f'Average {label_1}')\n",
    "  axes[2].imshow(label2_avg, cmap='gray')\n",
    "  axes[2].set_title(f'Average {label_2}')\n",
    "  plt.show()\n",
    "\n",
    "Let's compare King and Knight\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To help the interpretation, consider the following guide:\n",
    "* You are comparing label_1 to label_2\n",
    "* In the Difference Between Averages plot, the darker area shows where both average images are similar. The lighter area shows where average images are different\n",
    "* In this dataset, the contrast may not provide much insight since there is a small number of images per label.\n",
    "\n",
    "contrast_between_2_labels_data_as_array(X=X, y=y,\n",
    "                          label_1='King',\n",
    "                          label_2='Knight',\n",
    "                          figsize=(15,20)\n",
    "                          )\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The same note from the previous section applies here:\n",
    "* There will be datasets where the images in a given label will have distinct shapes or patterns, and contrast from a averages study may not provide the same amount of insights as we see in the chess dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis - Unit 03 - Real Datasets - Part 02\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Understand the differences for image datasets folder structure, and split folders into train, validation and test sets\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Let's extract the data we will be using\n",
    "with ZipFile('Chess.zip', 'r') as chessZip:\n",
    "   chessZip.extractall()\n",
    "with ZipFile('Covid19-dataset.zip', 'r') as covidZip:\n",
    "   covidZip.extractall()\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Image Analysis - Real Datasets - Part 02\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In the last unit, we used the Chess dataset, where a single folder hosted a set of sub-folders. Each sub-folder is related to a label. In each subfolder, you found a set of images\n",
    "\n",
    "* For the ML image classification task, we are interested in having a standardised way to arrange the files in a folder. Before doing any Image Analysis and ML on images, we have to organise the dataset folders.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> As a recap, our images could be arranged in these 3 formats\n",
    "  * One folder (with subfolders as the labels)\n",
    "  * Two folders (like Train and Test)\n",
    "  * Or three folders (with Train, Validation and Test)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> Ultimately we want to have **three folders: Train, Validation and Test**.\n",
    "\n",
    "\n",
    "The image below shows three potential folder structures. The first on the left shows one folder (with subfolders as the labels), the central piece shows two folders (like Train and Test set folders), and the last on the right shows three folders (with Train, Validation and Test)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\">  Again, we are interested in having a 3-folder structure. We will need to move files between folders programmatically. \n",
    "* The reason to have three folders is that for the process of fitting a model, we need 3 data sets: train, validation and test sets; as we have previously studied\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's split into two possibilities:\n",
    "* The dataset comes with one folder\n",
    "* The dataset comes with two folders (either Train/Test or Train/Validation). We will stick with the Train/Test convention\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are going to use a workflow:\n",
    "* 1 - Delete non-image files\n",
    "* 2 - Split Train, Validation, Test Set\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### The dataset comes with one folder\n",
    "\n",
    "We will use the same [Chess dataset](https://www.kaggle.com/niteshfre/chessman-image-dataset) to demonstrate how to arrange it into **three folders: Train, Validation and Test**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Split Train, Validation, Test Set\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We assume there is one folder that holds a set of folders that represent the label. In each sub-folder, we find the images related to each label.\n",
    "* Read the pseudo-code function to understand the function objective\n",
    "  * It is normal and okay if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "    \"\"\"\n",
    "    logic\n",
    "    - There is one folder that holds a set of folders that represent the label. \n",
    "    In each sub-folder, we find the images related to each label\n",
    "    - you provide the ratio for train, validation and test set. they should sum 1.0\n",
    "    - it will generate three folders (train, validation and test). In each folder, \n",
    "    there will be a set of subfolders related to each label. The proportion of a given \n",
    "    label across folders (train, validation, set), is set with train_set_ratio, validation_set_ratio, \n",
    "    and test_set_ratio parameters\n",
    "    \"\"\"\n",
    "\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum 1.0\")\n",
    "        return\n",
    "\n",
    "    # gets labels\n",
    "    labels = os.listdir(my_data_dir)  # it should get only the folder name\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        # hack: sometimes, in a jupyter notebook session, a temporary/invisible\n",
    "        # folder called .ipynb_checkpoints appears; we don't want it, so we remove it from the labels list\n",
    "        labels = [item for item in labels if '.ipynb_checkpoints' not in item]\n",
    "\n",
    "        # create the train, validation, and test folders with labels sub-folder\n",
    "        for folder in ['train', 'validation', 'test']:\n",
    "            for label in labels:\n",
    "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
    "\n",
    "        for label in labels:\n",
    "\n",
    "            files = os.listdir(my_data_dir + '/' + label)\n",
    "            random.shuffle(files)\n",
    "\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # move the given file to a train set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
    "\n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
    "                    # move the given file to a validation set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
    "\n",
    "                else:\n",
    "                    # move the given file to the test set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
    "\n",
    "                count += 1\n",
    "            os.rmdir(my_data_dir + '/' + label)\n",
    "\n",
    "\n",
    "Let's display the folders within the Chess folder.\n",
    "\n",
    "!ls Chess\n",
    "\n",
    "Within the Chess folder, we see there are three further folders, these are related to the dataset labels, let's display the content of the folder named Bishop\n",
    "\n",
    "* We now see the images inside the Bishop folder; notice we have jpg, gif, and png file extensions\n",
    "\n",
    "!ls Chess/Bishop\n",
    "\n",
    "We will split allocating 65% to the train set, 15% to validation, and 20% to the test set\n",
    "\n",
    "split_train_validation_test_images(my_data_dir='Chess',\n",
    "                                   train_set_ratio=0.65,\n",
    "                                   validation_set_ratio=0.15,\n",
    "                                   test_set_ratio=0.2)\n",
    "\n",
    "You can see how the folder structure changed, and now within the Chess folder, we have the folders test, train, validation\n",
    "\n",
    "!ls Chess\n",
    "\n",
    "If you look inside the train folder, you will see folders for Bishop, King, and Knight\n",
    "\n",
    "!ls Chess/train\n",
    "\n",
    "We will use [covid19 image datasets](https://www.kaggle.com/pranavraikokte/covid19-image-dataset), which are made using a set of Chest X-rays arranged in the Train and Test Set\n",
    "* We will demonstrate how to arrange into three folders: Train, Validation and Test\n",
    "\n",
    "---\n",
    "\n",
    "#### Split Train, Validation, Test Set\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The folders are split into Train and Test sets already. \n",
    "* We want to get part of the data from the train and assign it to a validation folder\n",
    "  * It is normal and okay if, at first, you don't understand all the code from the function below. The central point is to make sense of the pseudo-code and understand the function parameters.\n",
    "\n",
    "!ls Covid19-dataset\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "\n",
    "def split_validation_from_train_set(my_data_dir, train_set_folder_name, train_set_ratio):\n",
    "\n",
    "    if train_set_ratio >= 1.0 or train_set_ratio < 0:\n",
    "        print(\"train_set_ratio should be positive and smaller than 1.0\")\n",
    "        return\n",
    "\n",
    "    # define the train set dir\n",
    "    train_set_dir = my_data_dir + '/' + train_set_folder_name\n",
    "    directory_list = os.listdir(my_data_dir)\n",
    "\n",
    "    # gets the labels\n",
    "    labels = os.listdir(train_set_dir)\n",
    "    \n",
    "    if 'validation' in directory_list:\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        # hack: sometimes, in a jupyter notebook session, a temporary/invisible\n",
    "        # folder called .ipynb_checkpoints appears; we don't want it, so we remove it from the labels list\n",
    "        labels = [item for item in labels if '.ipynb_checkpoints' not in item]\n",
    "\n",
    "        for label in labels:  # create a validation folder\n",
    "            os.makedirs(name=my_data_dir + '/validation/' + label)\n",
    "\n",
    "        for label in labels:\n",
    "            files = os.listdir(train_set_dir + '/' + label)\n",
    "            random.shuffle(files)\n",
    "            train_set_files_qty = int(len(files) * (1-train_set_ratio))\n",
    "\n",
    "            count = 1\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # move the given file to a validation set\n",
    "                    shutil.move(train_set_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We provide the data directory, the train_set_folder_name and a train_set_ratio of 0.7, which means 70% of data from the train set will remain in the train set, and the difference, 30% of the train set, will go to the validation set\n",
    "\n",
    "split_validation_from_train_set(my_data_dir= 'Covid19-dataset',\n",
    "                                train_set_folder_name = 'train',\n",
    "                                train_set_ratio=0.8)\n",
    "\n",
    "If you check the folder structure of the Covid19-dataset, you will see it now contains folders for test, train, and validation\n",
    "\n",
    "!ls Covid19-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
