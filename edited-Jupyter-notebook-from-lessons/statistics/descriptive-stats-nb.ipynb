{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - Unit 01: Overview\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%201%20-%20Lesson%20Learning%20Outcome.png\"> Lesson Learning Outcome\n",
    "\n",
    "* **Descriptive statistics Lesson is made of 4 units.**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Understand the concepts around descriptive statistics, including outliers\n",
    "  * Exercise the concepts of Central tendency, Variability\n",
    "  * Visualise your data to understand better Descriptive Statistics in Numerical and Categorical Data\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Understand the major concepts around descriptive statistics\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use Pandas the majority of the time for this lesson. We will use Pingouin (an open-source statistical package based mostly on Pandas and NumPy) for QQ plots.\n",
    "\n",
    "---\n",
    "\n",
    "* Descriptive statistics provide a simple **summary** of the sample. It can be either quantitative or visual. \n",
    "  *  It provides the basis for analysis and will allow additional and more extensive investigations.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Question%20mark%20icon.png\n",
    "\">\n",
    " **Why do we study Descriptive statistics?**\n",
    "* Because Machine Learning algorithms are based on statistical models, understanding your data profile is critical to select the appropriate algorithm that best fits your data.\n",
    "\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%203%20-%20Additional%20Learning%20Context.png\"> Additional Context for Learning\n",
    "\n",
    "* We encourage you to:\n",
    "  * Add **code cells and try out** other possibilities, play around with parameter values in a function/method, or consider additional function parameters etc.\n",
    "  * Also, **add your own comments** to the cells. It can help you to consolidate your learning. \n",
    "\n",
    "\n",
    "* Parameters in given function/method\n",
    "  * As you may expect, a given function in a package may contain multiple parameters. \n",
    "  * Some of them are mandatory to declare; some have pre-defined values, and some are optional. We will cover the most common parameters used/employed in Data Science for a particular function/method. \n",
    "  * However, you may seek additional in the respective package documentation, where you will find instructions on how to use a given function/method. The studied packages are open source, so this documentation is public.\n",
    "  * **For Pandas, the link is [here](https://pandas.pydata.org/)**.\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Unit 01: Descriptive Statistics Overview\n",
    "\n",
    "We will cover the following concepts in this lesson\n",
    "* Distribution\n",
    "* Data type\n",
    "* Descriptive Statistics\n",
    "* Population and sample\n",
    "* Outlier\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Distribution\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let’s start by understanding what exactly distribution means. The term “distribution ” in data science or statistics usually means a probability distribution. You can think of a distribution as the spread of the values across a range.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Distribution is simply a function that provides the possible value of a variable and how often they occur. A probability distribution is a mathematical function that provides the possibilities of occurrence of various possible outcomes that can occur in an experiment.\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Data Type\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Before moving on, let's study data types for this lesson. A variable is any characteristic, behaviour, category, or number that can be measured or counted. Here are the types we are most interested in this lesson\n",
    "* Numerical\n",
    "* Categorical\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Numerical\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Numerical variables where values are numbers can be discrete or continuous. The difference between these relies on the following:\n",
    "* A continuous variable may contain any value in a range. For example, how much you spent in the market this week, the price of your mobile phone or the time, in seconds, you spent today in this lesson. These values can be a fraction; you may have spent 52.34 euros this week in the market.\n",
    "* Discrete means that there are only particular valid values, for example:\n",
    " - Number of times you went to the market this week (in this case, the values are not fractions)\n",
    " - Shoe size, like 6, 6.5, 7, 7.5, 8, 8.5 (note the values are fractions, but the values are not in a continuous range, only particular values are allowed)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Categorical\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Categorical variables are selected from a group of labels. For example, a coin toss can be heads or tails. Marital status can be single, married, divorced or other. Colour can be yellow, red, purple or blue.\n",
    "* The cardinality is the number of different labels it can have. In our previous examples, a coin toss had two, marital status three, and colour four\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> They can be broken down into **ordinal** or **nominal**.\n",
    "* An ordinal variable can be related to an order, like days of the week or student grade (fail, pass, pass with honour). \n",
    "* On the other hand, nominal variables don’t relate to a specific order, like preferred colour: which can be either blue, green, or yellow, and in this case, there is no specific order or rank.\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In your career, you might be in a situation where a categorical variable will be encoded as a number; for example, a test result can be encoded as 0 for fail and 1 for pass. \n",
    "* The data practitioner should consider the context and realise that, in this case, it is not a discrete variable but a categorical variable that was encoded\n",
    "* The other edge case is for IDs. Typically when you subscribe to a service, say a mobile phone, the company may generate a unique ID for you. This ID may be a set of numbers, but that doesn’t mean it makes sense to perform calculations with it. It may be better framed as a categorical variable\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Descriptive statistics\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Descriptive statistics is about describing and summarising the data:\n",
    "  * via a **quantitative approach** (numerical summary) and \n",
    "  * using a **graphical representation** (plots).\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in **summarising the dataset's variables**. \n",
    "  * If you describe one variable, that is univariate analysis.\n",
    "  * If you study two variables at once, bivariate. \n",
    "  * If you study more than 2, multivariate.\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We typically break down descriptive statistics into two major studies:\n",
    "  * **Central tendency**\n",
    "  * **Variability** \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Population and Sample\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We should be aware of the **population and sample** concept when analysing data.\n",
    "  * Population is all existing elements from that particular variable. In practical terms, a population has many elements, making it hard to collect all. \n",
    "    * Imagine if you want to collect people's preferences on pizza, hot dogs or barbecue in your country. That will likely be a lot of people. Collecting data from a lot of people means a lot of energy, time and money.\n",
    "  * On the other hand, a sample is a part of a population, which ideally preserves the statistical characteristics if the sample size is statistically significant. That allows us to draw inferences about the population based on relevant samples. The larger the sample, the smaller the error when compared to the whole population.\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Outliers\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In the workplace, you will face outliers, data points that differ from most of the data.\n",
    "\n",
    "* To understand outliers, we would have to come back to the data collection moment and make sense of its context and conditions since maybe an error might have happened for that given data point, or eventually, that data point is an observation of new behaviour. However, sometimes it is difficult to access the data collection moment,\n",
    "\n",
    "* There may be multiple reasons for outliers, like a new natural behaviour of the data, an error in the data collection process, due to eventually human error/bias, equipment not being calibrated etc.\n",
    "\n",
    "* There is a separate section in this lesson to make sense of outliers. A future lesson will dive further into handling outliers; the scope now is to make sense of it.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - Unit 02: Central Tendency\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Learn and apply the concepts of central tendency: mean, median and mode\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\">Central Tendency\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Before we start studying Central Tendency, let's assess the data we will study.\n",
    "  * The dataset was generated using NumPy random module and showed the following distributions: Normal, Exponential, Poisson, and Uniform\n",
    "  * There is a column called Positive Skewed and Negative Skewed. Skewness is a measure of symmetry. Distribution is symmetric when it looks the same to the left and right of the centre point. It is horizontally mirrored. We will study this measure in more detail; however, for now, we just want to cover the concept\n",
    "  * We are rounding the numbers with .round(). We are interested in values up to 3 decimal points\n",
    "\n",
    "  \n",
    "\n",
    "from scipy.stats import skewnorm\n",
    "np.random.seed(seed=1)\n",
    "size=1000\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=2, size=int(size/2) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/2) ) \n",
    "bi_modal = np.concatenate([X1, X2])\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=4, size=int(size/4) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/4) ) \n",
    "X3 = np.random.normal(loc=0, scale=2, size=int(size/4) ) \n",
    "X4 = np.random.normal(loc=80, scale=2, size=int(size/4) ) \n",
    "multi_modal = np.concatenate([X1, X2, X3, X4])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data={'Normal':np.random.normal(loc=0, scale=2, size=size),\n",
    "                        \"Positive Skewed\": skewnorm.rvs(a=10, size=size),\n",
    "                        \"Negative Skewed\": skewnorm.rvs(a=-10, size=size),\n",
    "                        \"Exponential\":np.random.exponential(scale=20,size=size),\n",
    "                        \"Uniform\":np.random.uniform(low=0.0, high=1.0, size=size),\n",
    "                        \"Bimodal\":  bi_modal,\n",
    "                        \"Multimodal\":  multi_modal,\n",
    "                        \"Poisson\":np.random.poisson(lam=1.0, size=size),\n",
    "                        \"Discrete\": np.random.choice([10,12,14,15,16,17,20],size=size),\n",
    "                        }).round(3)\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "Let's plot the distribution for each column\n",
    "* We will loop over each DataFrame column, create a figure and plot a histogram using `sns.histplot()`\n",
    "* Pay attention to the shapes and in which range in the x-axis is most frequent, in other words, where there is a higher \"count\"\n",
    "\n",
    "for col in df.columns:\n",
    "  plt.figure(figsize=(8,4))\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  plt.xlabel(\" \")\n",
    "  plt.show();\n",
    "  print(\"\\n\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Central tendency helps provide **figures to summarise** the data. We will start studying\n",
    "* Mean\n",
    "* Median \n",
    "* Mode\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Mean\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Mean, or average, is defined as the **measure of the spread of the data around that sample**.\n",
    "*  It is the sum of all elements divided by the total number of observations. \n",
    "\n",
    "To calculate the DataFrame mean, just use the method `.mean()` to see mean levels for each numerical variable. The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)\n",
    "\n",
    "df.mean()\n",
    "\n",
    "Let's consider the normal distribution from DataFrame `df` and plot it\n",
    "\n",
    "col = 'Normal'\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "plt.show()\n",
    "\n",
    "Let's now add the mean level to the histogram to understand better where the mean lies.\n",
    "* A quick note on `plt.text()`: we programmatically set the text position. We use `x` as the mean plus an offset, so the text is not on the top of the line. The offset we used is a fraction of the value from the standard deviation. It could be any other figure/metric, but the trick finds a slight offset to the text. We will explain later the concept and applications of standard deviation. For `y', we gathered the y-axis range with `.get_ylim()` and used the upper value with [1], so we could access the \"ceiling\" of the graph. Then, to increase readability, we shifted this value a bit by multiplying by 0.9 - this number is arbitrary; it's just for readability purposes.\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "plt.show()\n",
    "\n",
    "You already saw the distribution shape for all variables. Next, we will scan over the variables and will plot their distribution. \n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> **Before plotting, could you imagine where the mean level would be? Go back to the previous graphs with all histograms and guess where the mean level would be positioned**\n",
    "* ONLY after doing that, run the cell below\n",
    "\n",
    "for col in df.columns:\n",
    "\n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Median\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The Median is the element that **divides the data into two equal parts**. \n",
    "  * It is calculated by arranging the data in ascending or descending order.\n",
    "    * Then, if the number of elements is odd, it is given to the middle element in the arranged values. \n",
    "    * If the number of observations is even, the median is given by the mean of the two middle elements\n",
    "\n",
    "To calculate the DataFrame median, just use the method `.median()` to see median levels for each numerical variable. The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html)\n",
    "\n",
    "df.median()\n",
    "\n",
    "Let's plot the distribution, the median and the mean for normal distribution\n",
    "  * You will notice mean and median levels are the same in a normal distribution. A normal distribution is one that is symmetrical around the mean.\n",
    "  * We are running the same code from the previous section. The difference is that we are adding a line and text for the median level \n",
    "\n",
    "col = 'Normal'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "plt.axvline(df[col].median(), color='k', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.70, s='Median', fontsize=15, c='k')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "We will again plot all the columns from df, showing the mean and the median\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Before plotting, could you guess what the mean and median level would be?\n",
    "* Go back to the previous set of histograms and visualise where the median level would be. Once you finish this small task, run the cell below.\n",
    "\n",
    "for col in df.columns:\n",
    "\n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "  plt.axvline(df[col].median(), color='k', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.70, s='Median', fontsize=15, c='k')\n",
    "\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Mode\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Mode is the **most common element in the data**, the one that appears most often.\n",
    "  * If there is only one number, it is called Uni-modal.\n",
    "  * If there are two numbers, it is called Bi-modal.\n",
    "  * If there are more than two modes, it is called Multi-modal.\n",
    "\n",
    "To calculate the DataFrame mean, just use the method `.mode()` to see mode levels for each numerical variable. The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mode.html)\n",
    "* You will notice that the variables may contain more than one mode; This is fine; that just means that the given distribution has more than one number/element that is typically frequent. For **simplicity**, we will plot only the most frequent element in the upcoming exercise. We do that by gathering the first element with [0]\n",
    "\n",
    "df.mode()\n",
    "\n",
    "Consider the Normal Distribution. You will notice that mean, median and mode have similar levels\n",
    "* We are running the same code from the previous section. The difference is that we are adding a line and text for the mode level\n",
    "\n",
    "col = 'Normal'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "plt.axvline(df[col].median(), color='k', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.70, s='Median', fontsize=15, c='k')\n",
    "\n",
    "plt.axvline(df[col].mode()[0], color='g', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mode()[0] + df[col].std()/8 , y=axes.get_ylim()[1] * 0.50, s='Mode', fontsize=15, c='g')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "We will scan over the variables and will plot their distribution.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Pay attention to the central figures (or central tendency elements) from your data: **mean, median, and mode level**. \n",
    "* Are they different? Much different?\n",
    "* How are they positioned? For example: is the mean greater than the median?\n",
    "\n",
    "for col in df.columns:\n",
    "    \n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "  plt.axvline(df[col].median(), color='k', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.70, s='Median', fontsize=15, c='k')\n",
    "\n",
    "  plt.axvline(df[col].mode()[0], color='g', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mode()[0] + df[col].std()/8 , y=axes.get_ylim()[1] * 0.50, s='Mode', fontsize=15, c='g')\n",
    "\n",
    "\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE**: Select one of the suggested datasets and explore the central tendency of the numerical variables\n",
    "* You will see a set of suggestions; you may change the `dataset` variable to pick your data\n",
    "\n",
    "dataset = 'diamonds'  # 'penguins' 'iris' ,  'tips'  , 'mpg' , 'diamonds'\n",
    "df = (sns.load_dataset(dataset)\n",
    "      .sample(n=200,random_state=1)\n",
    "      .select_dtypes(exclude=['object', 'category'] # for some reason seaborn datasets sometimes come with \n",
    "                                                    # variables' type marked as category\n",
    "                                                    # instead of object.\n",
    "                     )) \n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "Examine the distribution shape for the variables. Ask yourself:\n",
    "* What is the distribution shape?\n",
    "* Do they look like the distributions (normal, exponential, multimodal etc.) we saw in this unit? Or does it look like a combination of shapes?\n",
    "* What is the range (in the x-axis) that the data is most frequent?\n",
    "\n",
    "for col in df.columns:\n",
    "    \n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "  plt.axvline(df[col].median(), color='k', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.70, s='Median', fontsize=15, c='k')\n",
    "\n",
    "  plt.axvline(df[col].mode()[0], color='g', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mode()[0] + df[col].std()/8 , y=axes.get_ylim()[1] * 0.50, s='Mode', fontsize=15, c='g')\n",
    "\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - Unit 03: Variability\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Understand the concepts around descriptive statistics\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Variability\n",
    "\n",
    "\n",
    "Let's load the DataFrame df we used in the previous unit\n",
    "\n",
    "from scipy.stats import skewnorm\n",
    "np.random.seed(seed=1)\n",
    "size=800\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=2, size=int(size/2) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/2) ) \n",
    "bi_modal = np.concatenate([X1, X2])\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=4, size=int(size/4) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/4) ) \n",
    "X3 = np.random.normal(loc=0, scale=2, size=int(size/4) ) \n",
    "X4 = np.random.normal(loc=80, scale=2, size=int(size/4) ) \n",
    "multi_modal = np.concatenate([X1, X2, X3, X4])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data={'Normal':np.random.normal(loc=0, scale=2, size=size),\n",
    "                        \"Positive Skewed\": skewnorm.rvs(a=10, size=size),\n",
    "                        \"Negative Skewed\": skewnorm.rvs(a=-10, size=size),\n",
    "                        \"Exponential\":np.random.exponential(scale=20,size=size),\n",
    "                        \"Uniform\":np.random.uniform(low=0.0, high=1.0, size=size),\n",
    "                        \"Bimodal\":  bi_modal,\n",
    "                        \"Multimodal\":  multi_modal,\n",
    "                        \"Poisson\":np.random.poisson(lam=1.0, size=size),\n",
    "                        \"Discrete\": np.random.choice([10,12,14,15,16,17,20],size=size),\n",
    "                        }).round(3)\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "We are adding more columns to our DataFrame. They are normal distributions with different standard deviations: 1, 5 and 10. They were generated with `np.random.normal()`, and its documentation is [here](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html).\n",
    "* These new variables will help to illustrate better the concepts covered in this unit\n",
    "\n",
    "df['NormalStd_1']= np.random.normal(loc=0, scale=1, size=size)\n",
    "df['NormalStd_5']= np.random.normal(loc=0, scale=5, size=size)\n",
    "df['NormalStd_10']= np.random.normal(loc=0, scale=10, size=size)\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Measures of Variability. \n",
    "* We are interested in complementing the previous analysis with more information **by quantifying how the data is spread** by calculating:\n",
    "    * Variance\n",
    "    * Standard Deviation\n",
    "    * Skewness\n",
    "    * Kurtosis\n",
    "    * Percentiles and Quartiles\n",
    "    * Range\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Variance\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Variance shows the spread of the data around the mean; it is a number that **tells how far/close the data points are from the mean**\n",
    "  * To calculate the variance from your numerical data in your DataFrame or Series, use the method **.var()**\n",
    "\n",
    "df.var()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Standard Deviation\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Standard deviation is also related to data spread. It is also known as sigma, and the symbol is **σ**.\n",
    "  * It measures the **dispersion of the data from the mean** in either direction\n",
    "\n",
    "* You can calculate the standard deviation from your DataFrame or Series either by applying the square root (using `np.sqrt()`, for example) of variance or using the method `.std()`.  The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html)\n",
    "\n",
    "np.sqrt(df.var())\n",
    "\n",
    "The most common approach is with `.std()`.\n",
    "\n",
    "\n",
    "df.std()\n",
    "\n",
    "You can better understand the standard deviation by plotting its value in relation to the mean.\n",
    "  * In other words, consider your mean, and subtract/add one standard deviation\n",
    "  * In the cell below, we consider the normal distribution column and plot the mean and one standard deviation in relation to the mean, using what we learned from Matplotlib and Seaborn\n",
    "\n",
    "col = 'Normal'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "plt.axvline(df[col].mean() + df[col].std(), color='k', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s='+1σ', fontsize=15, c='k')\n",
    "\n",
    "plt.axvline(df[col].mean() - df[col].std(), color='k', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=-df[col].mean() - df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.65, s='-1σ', fontsize=15, c='k')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Let's loop over all columns now\n",
    "* Pay attention to those which extend the data deviation or change around the mean\n",
    "\n",
    "for col in df.columns:\n",
    "\n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "  plt.axvline(df[col].mean() + df[col].std(), color='g', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s='+1σ', fontsize=15, c='g')\n",
    "\n",
    "  plt.axvline(df[col].mean() - df[col].std(), color='g', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() - df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s='-1σ', fontsize=15, c='g')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> There is an empirical rule for a normal distribution that 99.7% (or almost all of the observed data) is within **3 standard deviations** of the mean. \n",
    "* Also, 68% of the data falls within one standard deviation and 95% per cent within two standard deviations. Let's check that\n",
    "* Here, we plot the mean, and three standard deviations from the mean, so we can check if almost all data falls into the interval of 3 standard deviations in a normal distribution\n",
    "\n",
    "col = 'Normal'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "for num in[1,2,3]:\n",
    "  plt.axvline(df[col].mean() + num * df[col].std(), color='g', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].mean() + num * df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s=f'+{num}σ', fontsize=9, c='g')\n",
    "\n",
    "  plt.axvline(df[col].mean() - num * df[col].std(), color='g', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].mean() - num * df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s=f'-{num}σ', fontsize=9, c='g')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's check if this behaviour happens with other types of distributions.\n",
    "* Note that there are variables where the distribution is inside the positive and negative range of 3 standard deviations; some don't reach two standard deviations of spread.\n",
    "  * A normal distribution is one where there is symmetrical distribution around the mean. The values less than one standard deviation away from the mean account for 68.27% of the total, while two standard deviations from the mean account for 95.45% and three standard deviations account for 99.73%.\n",
    "  * This fact makes standard deviation a useful diagnostic. If 1 in every 100 measurements is outside three sigmas, there is no problem. You have an issue if two or more are outside three sigmas. Something has changed in the distribution.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> At the same time, there are variables, like log-normal, where its values go much further than three standard deviations of spread\n",
    "\n",
    "for col in df.columns:\n",
    "\n",
    "  fig, axes = plt.subplots(figsize=(10,6))\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  plt.axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].mean() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.90, s='Mean', fontsize=15, c='r')\n",
    "\n",
    "  for num in[1,2,3]:\n",
    "    plt.axvline(df[col].mean() + num * df[col].std(), color='g', linestyle='dashed', linewidth=1.5)\n",
    "    plt.text(x=df[col].mean() + num * df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s=f'+{num}σ', fontsize=9, c='g')\n",
    "\n",
    "    plt.axvline(df[col].mean() - num * df[col].std(), color='g', linestyle='dashed', linewidth=1.5)\n",
    "    plt.text(x=df[col].mean() - num * df[col].std() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.75, s=f'-{num}σ', fontsize=9, c='g')\n",
    "\n",
    "\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **Quick QUIZ**\n",
    "* If you were a machine, **which type of distribution would you ideally like to work on?** Which is more friendly so far?\n",
    "  * We hope you would say the **normal distribution** since we can easily explain all points using mean and standard deviation\n",
    "  * **Other distributions** can also be explained; however, a normal distribution is easiest.\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Skewness\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Skewness is the asymmetry of the data. \n",
    "  * Distribution is symmetric when it looks the same to the left and right of the centre point. It is horizontally mirrored.\n",
    "    * The closer to zero, the less skewed the data is, and the more symmetrical the data is.\n",
    "    * Positive Skewness happens when the tail on the right side is longer. \n",
    "    * Negative Skewness happens when the tail of the left side of the distribution is longer.\n",
    "\n",
    "* If, for example, your values are all positive but are close to zero, then your distribution will be skewed as you cannot have negative values. This is considered a distribution bound by 0. This equally applies to any hard boundary for your value\n",
    "\n",
    "* To calculate skewness in your DataFrame or Series, use `.skew()`. The documentation is [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html)\n",
    "\n",
    "df.skew()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Can you correlate the skew levels and the distribution shape?\n",
    "  * You will notice that positive or negative skewness levels above 2 create a significant asymmetry in your data. Check the Exponential column\n",
    "\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(figsize=(10,5))\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  plt.text(x=df[col].min(), y=axes.get_ylim()[1] * 0.95, s=f\"Skewness: {df[col].skew().round(2)}\", fontsize=15, c='r')\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Kurtosis\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Kurtosis relates to studying the **tails of the distribution**. \n",
    "  * It is a measure of outliers in the distribution \n",
    "  * A distribution with high kurtosis tends to have significant tails or many outliers \n",
    "  * On the other hand, a distribution with low kurtosis tends to have a light tail or few outliers\n",
    "\n",
    "* An outlier is a value that is not statistically part of the distribution. An outlier can be something that is very unlikely but also might indicate a mismeasure or other error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To calculate kurtosis in your DataFrame or Series, use `.kurtosis()`. The documentation is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.kurtosis.html)\n",
    "\n",
    "df.kurtosis()\n",
    "\n",
    "Compare the shape and kurtosis levels for your dataset variables. Can you correlate the kurtosis levels and the distribution shape?\n",
    "\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(figsize=(10,5))\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  plt.text(x=df[col].min(), y=axes.get_ylim()[1] * 0.95, s=f\"Kurtosis: {df[col].kurtosis().round(2)}\", fontsize=15, c='r')\n",
    "  plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Percentiles and Quartiles\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A Percentile is **all values below the given percentage**. \n",
    "* Let's use some examples so you can better understand:\n",
    "    * For example, the 50th percentile is all values below which 50% of the observations may be found. For example, if I tell you that your age is at the 50% percentile of your family, that means 50% of your family is younger than you\n",
    "    * In Data Science, we tend to work with **quartiles**, which are the percentiles divided into four parts. Therefore we have:\n",
    "      * First quartile (Q1 or 25th percentile)\n",
    "      * Second quartile (Q2 or 50th percentile or median) and \n",
    "      * Third quartile (Q3 or 75th percentile)\n",
    "    * The interquartile range (IQR) is the difference between the first and third quartile. \n",
    "      * This is useful in understanding the range where 50% of the most frequent data is.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To calculate quartiles in your DataFrame or Series, use `.quantile()`. The documentation is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)\n",
    "  * The argument is `q`, and accepts values between 0 and 1, which are the quantile to compute\n",
    "  * In the example below, we parse a list with\n",
    "    * 0: 0 percentile, in other other words, the min value\n",
    "    * 0.25: 1st quartile, or the value that 25% of data is below\n",
    "    * 0.50: 2nd quartile, or the value that 50% of data is below. Also known as the median.\n",
    "    * 0.75: 3rd quartile, or the value that 75% of data is below\n",
    "    * 1.00: 100 percentile, or the max value\n",
    "\n",
    "df.quantile(q=[0,0.25,0.50,0.75,1])\n",
    "\n",
    "---\n",
    "\n",
    "Let's check that in practical terms in a graph. Please note the following figures we saw in the previous table for a normal distribution\n",
    "  * **median**\n",
    "  * **range**: area delimited by Min and Max\n",
    "  * **IQR**: area delimited by 1Q and 3Q - This is useful in understanding the area where the 50% most frequent of the data is.\n",
    "\n",
    "col = 'Normal'\n",
    "map = pd.Series(data=[\"Min\",\"Q1\",\"Median\",\"Q3\",\"Max\"], index=[0,0.25,0.50,0.75,1])\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5))\n",
    "sns.histplot(data=df, x=col, kde=True)\n",
    "for quantile in [0, 0.25, 0.5, 0.75, 1]:\n",
    "  plt.axvline(df[col].quantile(q=quantile), color='g', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].quantile(q=quantile) + df[col].std()/10,\n",
    "           y=axes.get_ylim()[1] * 0.95,\n",
    "           s=f\"{map[quantile]}\", fontsize=10, c='g')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Let's scan over the variables and pay attention to the same figures (min, max, Q1, Q3, IQR, and Median)\n",
    "\n",
    "map = pd.Series(data=[\"Min\",\"Q1\",\"Median\",\"Q3\",\"Max\"], index=[0,0.25,0.50,0.75,1])\n",
    "\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(figsize=(10,5))\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "  for quantile in [0, 0.25, 0.5, 0.75, 1]:\n",
    "    plt.axvline(df[col].quantile(q=quantile), color='g', linestyle='dashed', linewidth=1.5)\n",
    "    plt.text(x=df[col].quantile(q=quantile) + df[col].std()/10, y=axes.get_ylim()[1] * 0.95, s=f\"{map[quantile]}\", fontsize=10, c='g')\n",
    "    \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> QQ Plot\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in assessing how close our data is to a normal distribution. For that, we use a QQ Plot (Quantile-Quantile plot)\n",
    "  * When the quantiles of two variables are plotted against each other, then the plot obtained is known as a QQ plot. \n",
    "  * This plot provides a summary of **whether the distributions of two variables are similar or not with respect to the locations.**\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> If we **compare** our **data** to a **normal distribution**, we are assessing if our data is normally distributed, then:\n",
    "* If your data has the profile of a normal distribution, it should roughly fall in a straight line\n",
    "\n",
    "  * Since this is a visual tool for comparison, results can also be quite subjective but nonetheless useful in the underlying understanding distribution of a variable(s).\n",
    "  * It is particularly useful in identifying a subtle bimodal or multimodal distribution that would not be visible from a gaussian plot. \n",
    "\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(10,4))\n",
    "  sns.histplot(data=df, x=col, kde=True,ax=axes[0])\n",
    "  axes[0].set_title(\"Histogram\")\n",
    "  pg.qqplot(df[col], dist='norm',ax=axes[1])\n",
    "  fig.suptitle(f\"{col} Distribution\")\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Range\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Range is  the difference between the **maximum and minimum** values of your distribution\n",
    "\n",
    "\n",
    "You can calculate the minimum values of your numerical data with `.min()`. The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html)\n",
    "\n",
    "df.min()\n",
    "\n",
    "You can calculate the max values of your numerical data with `.max()`. The documentation link is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html)\n",
    "\n",
    "df.max()\n",
    "\n",
    "The range of the data is the difference between max and min\n",
    "\n",
    "df.max() - df.min()\n",
    "\n",
    "Let's plot the data and check its range\n",
    "\n",
    "for col in df.columns:\n",
    "    \n",
    "  fig, axes = plt.subplots(figsize=(8,5))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "  plt.axvline(df[col].min(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].min() + df[col].std()/6 , y=axes.get_ylim()[1] * 0.90, s='Min', fontsize=15, c='r')\n",
    "\n",
    "  plt.axvline(df[col].max(), color='r', linestyle='dashed', linewidth=2)\n",
    "  plt.text(x=df[col].max() + df[col].std()/6 , y=axes.get_ylim()[1] * 0.9, s='Max', fontsize=15, c='r')\n",
    "\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - Unit 04: Categorical Data, Outliers and Summary Statistics\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Learn and interpret statistics for categorical data.\n",
    "* Understand and identify outliers\n",
    "* Interpret a summary statistics\n",
    "\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Categorical Data, Outliers and Summary Statistics\n",
    "\n",
    "In this unit, we will cover\n",
    "* Descriptive statistics on categorical data\n",
    "* Outliers\n",
    "* Summary Statistics\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Categorical Data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Descriptive statistics of categorical data (or object data type in Python) is interested in counting the frequencies from their levels\n",
    "\n",
    "Let's consider the following dataset. It has records for three different species of penguins collected from 3 islands in the Palmer Archipelago, Antarctica\n",
    "\n",
    "df = sns.load_dataset('penguins')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "We can use `.describe(include='all')` to calculate the descriptives statistics for categorical variables.\n",
    "* In the examples below we filtered the categorical variables with `.select_dtypes(include='object')`, to focus on categorical data only. But as you have seen in Pandas, it is not an issue to mix numerical and categorical data when using `.describe(include='all')`\n",
    "\n",
    "It shows the total non-null number of rows for a given column, how many unique levels it has, the most frequent level and its frequency.\n",
    "\n",
    "df.select_dtypes(include='object').describe(include='all')\n",
    "\n",
    "In addition, you can count the values for each categorical variable using `.value_counts()` while looping over all categorical variables\n",
    "\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "  print(f\"{df[col].value_counts()}  \\n\\n\")\n",
    "\n",
    "Finally, we can plot the categorical data in bar plots to visualize the univariate distribution\n",
    "* You may use the library you feel most comfortable with. In this case, we used Seaborn\n",
    "\n",
    "for col in df.select_dtypes(include='object'):\n",
    "  plt.figure(figsize=(10,4))\n",
    "  sns.countplot(data=df, x=col)\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Outliers\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Outliers are simply data points that are different from the majority of the data\n",
    "\n",
    "* Consider the dataset below. It holds records for waiter tips based on the day of the week, day time, total bill, gender, if it is a smoker table or not, and how many people were at the table.\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A rule of thumb used to define whether a given data point is an outlier is to determine if that data point is:\n",
    "* **1** - above Q3 +  1.5 x IQR or \n",
    "* **2** - below Q1 - 1.5 x IQR\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In the histograms below, you can check if the data is an outlier by checking everything that is **not** in between the **range from \"Q1 - 1.5 IQR\"** to **\"Q3 - 1.5 IQR\"**\n",
    "* We also place the median levels\n",
    "* You will notice that the outliers in this data set are located more to the right side of the distribution. However, this is just a circumstance; outliers can be on any side of the distribution\n",
    "\n",
    "for col in  df.select_dtypes(include='number').columns:\n",
    "\n",
    "  fig, axes = plt.subplots(figsize=(12,6))\n",
    "  plt.title(f\"{col} Distribution\")\n",
    "  sns.histplot(data=df, x=col, kde=True)\n",
    "\n",
    "  plt.axvline(df[col].median(), color='g', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].median() + df[col].std()/8 , y=axes.get_ylim()[1] * 0.95, s='Median', fontsize=10, c='g')\n",
    "\n",
    "\n",
    "  IQR = df[col].quantile(q=0.75) - df[col].quantile(q=0.25)\n",
    "\n",
    "  plt.axvline(df[col].quantile(q=0.25), color='r', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].quantile(q=0.25) + df[col].std()/10, y=axes.get_ylim()[1] * 0.90, s=\"Q1\", fontsize=10, c='r')\n",
    "\n",
    "  plt.axvline(df[col].quantile(q=0.25) - 1.5*IQR, color='k', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].quantile(q=0.25) - 1.5*IQR + df[col].std()/10, y=axes.get_ylim()[1] * 0.75, s=\"Q1 - 1.5IQR\", fontsize=10, c='k')\n",
    "  \n",
    "  plt.axvline(df[col].quantile(q=0.75), color='r', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].quantile(q=0.75) + df[col].std()/10, y=axes.get_ylim()[1] * 0.90, s=\"Q3\", fontsize=10, c='r')\n",
    "\n",
    "  plt.axvline(df[col].quantile(q=0.75) + 1.5*IQR, color='k', linestyle='dashed', linewidth=1.5)\n",
    "  plt.text(x=df[col].quantile(q=0.75) + 1.5*IQR + df[col].std()/10, y=axes.get_ylim()[1] * 0.65, s=\"Q3 + 1.5IQR\", fontsize=10, c='k')\n",
    "  \n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Just a quick recap on a boxplot and its major elements: min, max, median, IQR, and outliers\n",
    "* Note: you will notice that in the example below, there is no Q1 - 1.5 IQR since there is nothing below this interval. There is only the min value\n",
    "* On the other side, we find Q3 + 1.5 IQR, the outliers and the max value (which happens to be an outlier)\n",
    "\n",
    "\n",
    "You can check using a box plot and note the outliers marked as points\n",
    "\n",
    "for col in  df.select_dtypes(include='number').columns:\n",
    "  fig, axes = plt.subplots(figsize=(10,3))\n",
    "  sns.boxplot(data=df, x=col)\n",
    "\n",
    "  plt.title(f\"{col} Boxplot\")\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "Finally, you can combine both boxplots and histograms in a unique way for univariate analysis. It gives you more perspective in one single Figure: you can check the distribution shape and main figures\n",
    "* We considered the additional `gridspec_kw` argument at `plt.subplots()`, so we could control the proportional size of the Axes in the Figure. In this case, we want the first Axes - box plot - to occupy 15% of the Figure and the second Axes - histogram - to occupy 85% of the Figure\n",
    "\n",
    "for col in  df.select_dtypes(include='number').columns:\n",
    "  fig, axes = plt.subplots(nrows=2 ,ncols=1 ,figsize=(7,7), gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "  sns.boxplot(data=df, x=col, ax=axes[0])\n",
    "  sns.histplot(data=df, x=col, kde=True, ax=axes[1])\n",
    "  fig.suptitle(f\"{col} Distribution - Boxplot and Histogram\")\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Summary / Calculate Descriptive Statistics\n",
    "\n",
    "We combine `.describe()`, .`skew()` and `.kurtosis()` to analyze our numerical and categorical data\n",
    "\n",
    "* Consider the dataset below. It holds records for waiter tips based on the day of the week, day time, total bill, gender, if it is a smoker table or not, and how many people were at the table.\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "You will notice that, naturally, for categorical variables, we don't have skewness and kurtosis\n",
    "\n",
    "ser_skew = df.skew() # the result is a Pandas Series, which we will append to a DataFrame\n",
    "ser_skew.name = 'Skewness'\n",
    "\n",
    "ser_kurt = df.skew() # the result is a Pandas Series, we will append to a DataFrame\n",
    "ser_kurt.name = 'Kurtosis'\n",
    "\n",
    "SummaryStats = df.describe(include='all')\n",
    "SummaryStats = SummaryStats.append(ser_skew).append(ser_kurt)\n",
    "SummaryStats\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
