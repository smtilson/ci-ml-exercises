{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests - Unit 01: Overview, Shapiro and Chi-Squared\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%201%20-%20Lesson%20Learning%20Outcome.png\"> Lesson Learning Outcome\n",
    "\n",
    "* **Statistical Tests Lesson is made of 3 units.**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Understand and apply the concepts considered in a Statistical Test\n",
    "  * Conduct and interpret statistical tests like Shapiro Wilk, Chi Squared, T test, Paired T Test, ANOVA, Mann Whitney, Wilcoxon and Kruskal Wallis test\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "  * Understand and apply the concepts considered in a Statistical Test\n",
    "  * Conduct and interpret statistical tests using Shapiro Wilk and Chi Squared Test\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "* We will use Pandas and Pingouin (an open-source statistical package based mostly on Pandas and NumPy) libraries in this lesson.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Question%20mark%20icon.png\n",
    "\">\n",
    " **Why do we study Statistical Tests?**\n",
    "  * Because we can determine the differences or similarities between groups, we can also evaluate if a predictor variable is statistically important to a target variable.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%203%20-%20Additional%20Learning%20Context.png\"> Additional Context for Learning\n",
    "\n",
    "* We encourage you to:\n",
    "  * Add **code cells and try out** other possibilities, play around with parameter values in a function/method, or consider additional function parameters etc.\n",
    "  * Also, **add your own comments** to the cells. It can help you to consolidate your learning. \n",
    "\n",
    "* Parameters in given function/method\n",
    "  * As you may expect, a given function in a package may contain multiple parameters. \n",
    "  * Some of them are mandatory to declare; some have pre-defined values, and some are optional. We will cover the most common parameters used/employed in Data Science for a particular function/method. \n",
    "  * However, you may seek additional in the respective package documentation, where you will find instructions on how to use a given function/method. The studied packages are open source, so this documentation is public.\n",
    "  * **For Pandas, the link is [here](https://pandas.pydata.org/) and for Pingouin [here](https://pingouin-stats.org/api.html)**\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import pingouin as pg\n",
    "import scipy\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Statistical Tests Overview\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A statistical test has a mechanism to make a decision about a process. \n",
    "* **The idea is to see if there is enough evidence to accept or reject a hypothesis about the process.**\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Hypothesis Testing\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Hypothesis testing is a way of forming opinions or conclusions from the data we collect.\n",
    "\n",
    "* The data is used to choose between **two choices**, aka hypothesis or statements. In practical terms, the reasoning is done by comparing what we have observed to what we expected. \n",
    "* The available data will typically be a sample of the entire population.\n",
    "\n",
    "  * There is a **Null Hypothesis (H0)**, which consists of a statement about the sample data used. Typically it says there is no difference between groups.\n",
    "  * An **Alternative Hypothesis (H1)** is typically the research question and states that there is a difference between groups.\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Significance Level\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The Significance Level, or alpha, is the probability of rejecting the null hypothesis when it is true. \n",
    "* This means the percentage of risk we are okay to take while rejecting the null hypothesis.\n",
    "* This is a percentage that the researcher can set; however, it is frequently set at 5%, meaning there is a 5 in 100 chance of rejecting the null hypothesis when it is, in fact, true.\n",
    "  * However, depending on the topic you are researching (typically, high stakes), you may be more conservative and select a lower alpha level. For example, if you are testing a new drug that will cure cancer, you want to be very sure about your conclusions\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Test Statistic\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A Statistical test works by measuring a test statistic, which is a number that explains how different the relationship between the variables in your test is.\n",
    "* The method to calculate a test statistic varies between tests; for example, the formula for a test with two samples differs from a test with three samples. The test statistic compares differences between the samples.\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> P-value\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The p-value is considered a tool for deciding whether to reject the null hypothesis.\n",
    "\n",
    "* In a simple definition, a p-value is a probability that the null hypothesis is true. The smaller p-value, the stronger the evidence we have in favour of the alternative hypothesis. We will not focus on how it is calculated, like which statistics tables are used; let's keep it simple for the moment.\n",
    "\n",
    "* Once you have a p-value and alpha (or Significance level), you are in a position to make a statistical conclusion and interpret a statistical test.\n",
    "  * If the p-value is lower than the alpha, you have enough evidence to reject the null hypothesis\n",
    "  * If the p-value is not lower than alpha, you do not have enough evidence to reject the null hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Shapiro-Wilk\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  The Shapiro-Wilk tests if a given data is **normally distributed**\n",
    "* The null hypothesis states that the population is normally distributed.  The alternative hypothesis states that the population is not normally distributed\n",
    "* Thus, if the p-value is less than the chosen alpha level (typically set at 0.05), the null hypothesis is rejected, and there is evidence that the data tested is not normally distributed.\n",
    "\n",
    "\n",
    "First, let's generate some data to illustrate the concepts over the lesson, using the libraries we have learned so far\n",
    "\n",
    "from scipy.stats import skewnorm\n",
    "np.random.seed(seed=1)\n",
    "size=200\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=2, size=int(size/2) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/2) ) \n",
    "bi_modal = np.concatenate([X1, X2])\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=4, size=int(size/4) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/4) ) \n",
    "X3 = np.random.normal(loc=0, scale=2, size=int(size/4) ) \n",
    "X4 = np.random.normal(loc=80, scale=2, size=int(size/4) ) \n",
    "multi_modal = np.concatenate([X1, X2, X3, X4])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data={'Normal':np.random.normal(loc=0, scale=2, size=size),\n",
    "                        \"Positive Skewed\": skewnorm.rvs(a=10, size=size),\n",
    "                        \"Negative Skewed\": skewnorm.rvs(a=-10, size=size),\n",
    "                        \"Exponential\":np.random.exponential(scale=20,size=size),\n",
    "                        \"Uniform\":np.random.uniform(low=0.0, high=1.0, size=size),\n",
    "                        \"Bimodal\":  bi_modal,\n",
    "                        \"Multimodal\":  multi_modal,\n",
    "                        \"Poisson\":np.random.poisson(lam=1.0, size=size),\n",
    "                        \"Discrete\": np.random.choice([10,12,14,15,16,17,20],size=size),\n",
    "                        }).round(3)\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "\n",
    "Let's visualise the data distribution using a boxplot and histogram for all variables.\n",
    "* We loop on each variable and create a figure with two plots, one boxplot and one histogram\n",
    "\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(nrows=2 ,ncols=1 ,figsize=(7,7), gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "  sns.boxplot(data=df, x=col, ax=axes[0])\n",
    "  axes[0].set_xlabel(\" \")\n",
    "  sns.histplot(data=df, x=col, kde=True, ax=axes[1])\n",
    "  fig.suptitle(f\"{col} Distribution - Boxplot and Histogram\")\n",
    "  plt.show()\n",
    "  print(\"\\n\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We can test if all numerical columns in a DataFrame are normally distributed with `pg.normality()`.The function documentation is [here](https://pingouin-stats.org/generated/pingouin.normality.html). The arguments we parse are: `data`, `alpha=0.05` for the significance level\n",
    "* The output shows in the ``index`` each variable name and in the ``normal`` column whether a given variable is normally distributed or not.\n",
    "\n",
    "pg.normality(data=df, alpha=0.05)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note that in the previous example, each column holds a distinct numerical distribution.\n",
    "* However, your data may have a different arrangement.  If your data is in a long format, has numerical and categorical variables, and you want to know if the numerical variables are normally distributed based on a given category, you can use the `dv` and `group` arguments\n",
    "\n",
    "\n",
    "Consider the dataset below: It has records for three different species of penguins collected from 3 islands in the Palmer Archipelago, Antarctica\n",
    "\n",
    "df_pinguins = sns.load_dataset('penguins')\n",
    "print(df_pinguins.shape)\n",
    "df_pinguins.head(3)\n",
    "\n",
    "You can check if `bill_length_mm` (numerical variable) is normally distributed across `species` (categorical variable)\n",
    "* We add the `dv` (dependent variable) as `bill_length_mm` and `group` (grouping variable) as `species`\n",
    "* We note that only `bill_length_mm` in `Gentoo` species is not normally distributed\n",
    "\n",
    "pg.normality(data=df_pinguins, dv='bill_length_mm', group='species', alpha=0.05)\n",
    "\n",
    "However, you will notice that `bill_length_mm` itself is not normally distributed\n",
    "\n",
    "pg.normality(data=df_pinguins['bill_length_mm'], alpha=0.05)\n",
    "\n",
    "You can plot a histogram for `bill_length_mm`, and `bill_length_mm` per `species` to make sense of the distribution plot/shape and the shapiro results\n",
    "* bill_length_mm variable is not normally distributed\n",
    "* when you analyze bill_length_mm per species, Gentoo's bill_length_mm is not normally distributed\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **Note** The visuals may mislead you; what matters is the result of the statistical test\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,7))\n",
    "sns.histplot(data=df_pinguins, x='bill_length_mm', kde=True, ax=axes[0])\n",
    "sns.histplot(data=df_pinguins, x='bill_length_mm',hue='species' , kde=True, palette='Set2', ax=axes[1])\n",
    "plt.show();\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Chi-Squared Test (Goodness of Fit)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Chi-Squared Test measures if there is a significant difference between the expected frequencies and the observed frequencies in categorical variables\n",
    "\n",
    "\n",
    "* Hypothesis\n",
    "  * Null hypothesis – there is no difference in the frequency or the proportion of occurrences in each category\n",
    "  * Alternate hypothesis - there is a difference in the frequency or proportion of occurrences in each category\n",
    "\n",
    "\n",
    "Let's consider a built-in dataset from pingouin. It is a study on heart disease, where the target equals one, which indicates heart disease.\n",
    "\n",
    "df = pg.read_dataset('chi2_independence')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "Let's check target (heart disease) distribution with `.value_counts()`\n",
    "\n",
    "df['target'].value_counts()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's take target and fbs (that looks to define fasting blood sugar)\n",
    "* We ask ourselves, is fbs a good predictor for the target (heart disease)? Is there any significant association between them?\n",
    "\n",
    "Let's make a barplot to investigate `fbs` levels across different `target` levels\n",
    "* That shows the distribution of people that have/don't have heart disease and have/don't have fbs\n",
    "* It visually looks that the distribution of people with and without heart disease is similar to people with different fbs levels\n",
    "\n",
    "sns.countplot(x='fbs',hue='target',data=df)\n",
    "plt.show()\n",
    "\n",
    "We use `pg.chi2_independence()` to conduct Chi Square Test. The documentation link is [here](https://pingouin-stats.org/generated/pingouin.chi2_independence.html#pingouin.chi2_independence). The arguments we use are:\n",
    "* data, x and y as the variables for the chi squared test. y tends to be the target variable you are interested in analysing across a given feature (x)\n",
    "\n",
    "expected, observed, stats = pg.chi2_independence(data=df, x='fbs', y='target')\n",
    "\n",
    "The test summary (`stats`), has the result of the Pearson Chi-Square test\n",
    "\n",
    "\n",
    "stats\n",
    "\n",
    "We are interested in the ``pval`` from the ``pearson`` test.\n",
    "* We ``query`` from stats where `test == pearson` and grab `pval`\n",
    "\n",
    "stats.query(\"test == 'pearson'\")['pval']\n",
    "\n",
    "We consider our significance level alpha = 0.05. \n",
    "* Since ``p-value`` (0.744428) is greater than the alpha, we accept the null hypothesis.\n",
    "* Therefore there was not a significant association between `fbs` and `target`. \n",
    "  * `fbs` is not indicated to be a good predictor for `target`\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Now let's take `target` and `sex`\n",
    "\n",
    "* We ask ourselves, is `sex` a good predictor for the `target` (heart disease)?\n",
    "*  Is there any significant association between them?\n",
    "\n",
    "\n",
    "\n",
    "Let's make a barplot to investigate `sex` levels across different `target` levels\n",
    "* It visually looks that no heart disease (target = 0) proportion in one sex is different than the other.\n",
    "\n",
    "sns.countplot(data=df, x='sex', hue='target')\n",
    "plt.show()\n",
    "\n",
    "We conduct the Chi-Squared Test, where now `x='sex'`\n",
    "\n",
    "expected, observed, stats = pg.chi2_independence(data=df, x='sex', y='target')\n",
    "\n",
    "And extract p-value using the same rationale from the previous exercise\n",
    "\n",
    "stats.query(\"test == 'pearson'\")['pval']\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We consider our significance level alpha = 0.05.\n",
    "* Since pvalue (0.000002) is smaller than the alpha, we reject the null hypothesis.\n",
    "\n",
    "* Therefore there was a significant association between `sex` and `target`.\n",
    "  *  `sex` is indicated to be a good predictor for  the `target` (heart disease)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests - Unit 02: Parametric Statistical Tests\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "  * Conduct and interpret statistical tests using T test, Paired T test and ANOVA\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import pingouin as pg\n",
    "import scipy\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Parametric and Nonparametric Statistical Tests\n",
    "  \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> There are parametric and nonparametric statistical tests.\n",
    "* Depending on the normality of your data (meaning if it is a normal distribution or not), you may use a parametric test or a nonparametric test\n",
    "\n",
    "  * If it is normally distributed, we use a parametric test.\n",
    "  * If it is not, we use a nonparametric test.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **In this unit, we will cover parametric tests**\n",
    "\n",
    "----\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> T-test\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A t-test, also known as Student's t-test is a parametric test (the mean is the parameter) and can compute and test the difference between two sample means\n",
    "* In other words, it tests if the difference in the means is 0\n",
    "* Both samples should be normally distributed \n",
    "* It is developed by William Gosset of Guinness's Brewery\n",
    "* The samples should be **independent (or unpaired)**. \n",
    "  * For example, imagine we are evaluating the effect of a new drug treatment, and we enrol 200 people, then randomise half in the treatment group and half in the control group. In this case, we have two independent groups\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  The null hypothesis states that there are no significant levels of difference between the samples. The alternative hypothesis states that there are significant levels of difference between the samples.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's consider a DataFrame that has Col1 and Col2 columns made with NumPy function to create normally distributed data\n",
    "\n",
    "np.random.seed(123)\n",
    "size = 250\n",
    "df = pd.DataFrame(data={'Col1': np.random.normal(loc=7, scale=1, size=size),\n",
    "                        \"Col2\": np.random.normal(loc=8, scale=1.2, size=size)}\n",
    "                  )\n",
    "df.head()\n",
    "\n",
    "We check normality using `pg.normality()`, they are normally distributed, so we can use T-test to compare both.\n",
    "\n",
    "pg.normality(data=df, alpha=0.05)\n",
    "\n",
    "Let's plot both variables in a histogram and box plot and ask ourselves: **are they similar or different**?\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1 ,ncols=2 ,figsize=(12,5))\n",
    "\n",
    "sns.histplot(data=df, kde=True, ax=axes[0])\n",
    "for col in df.columns: \n",
    "  axes[0].axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=1)\n",
    "sns.boxplot(data=df, ax=axes[1])\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "We conduct a T-test using `pg.ttest()`. The documentation is found [here](https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest). We parse both numerical distributions in `x` and `y`\n",
    "* We are interested in the p-value\n",
    "\n",
    "pg.ttest(x=df['Col1'], y=df['Col2'])\n",
    "\n",
    "At this moment, we are interested in checking the `p-val`, which is the p-value. We get that using `.loc[]`\n",
    "\n",
    "pg.ttest(df['Col1'],df['Col2']).loc['T-test','p-val']\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We consider our significant level alpha = 0.05. \n",
    "* Since p-value (3.32e-20) is smaller than the alpha, we reject the null hypothesis.\n",
    "\n",
    "* Therefore there is enough statistical difference between X and Y levels. **Their levels are different!**\n",
    "  * It isn't easy to make sense of the interpretation. The columns' names are Col1 and Col2. But frame them as math exam scores from 2 distinct groups. The understanding, in this case, is that there is a difference between them, where the second has higher levels\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's consider another exercise and create a DataFrame that has Col3 and Col4 columns made with NumPy function to create normally distributed data\n",
    "\n",
    "np.random.seed(3)\n",
    "size = 250\n",
    "df = pd.DataFrame(data={'Col3':  np.random.normal(loc=7, scale=1, size=size),\n",
    "                        \"Col4\":np.random.normal(loc=7.2, scale=1, size=size)})\n",
    "df.head(3)\n",
    "\n",
    "We confirm normality with `pg.normality()`. They are normally distributed.\n",
    "\n",
    "pg.normality(df, alpha=0.05)\n",
    "\n",
    "Let's plot both variables in a histogram and box plot and ask ourselves: are they similarly distributed or different?\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1 ,ncols=2 ,figsize=(12,5))\n",
    "\n",
    "sns.histplot(data=df, kde=True, ax=axes[0])\n",
    "for col in df.columns: \n",
    "  axes[0].axvline(df[col].mean(), color='r', linestyle='dashed', linewidth=1)\n",
    "sns.boxplot(data=df, ax=axes[1])\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "We conduct a T-test using `pg.ttest()`.\n",
    "\n",
    "pg.ttest(df['Col3'],df['Col4'])\n",
    "\n",
    "And we extract the `p-val`, which is the p-value\n",
    "\n",
    "pg.ttest(df['Col3'],df['Col4']).loc['T-test','p-val']\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We consider our significant level alpha = 0.05. \n",
    "* Since p-value (0.0949) is greater than the alpha, we accept the null hypothesis.\n",
    "\n",
    "* Therefore there is not enough statistical difference between X and Y levels. Their levels are the same!\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Paired Student’s t-test\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  A Paired Student’s t-test is a parametric test (the mean is the parameter) and tests for the difference between two sample means. Both samples should be normally distributed.\n",
    "\n",
    "* The samples should be **dependent (or paired)**\n",
    "  * It should be a sample of matched pairs. \n",
    "  * For example, **imagine the same group is tested twice**. Say you want to examine the difference between people's scores on a test before and after a training intervention \n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  The null hypothesis states that there are no significant levels of difference between the samples. The alternative hypothesis states that there are significant levels of difference between the samples.\n",
    "\n",
    "\n",
    "\n",
    "Consider a dataset from pingouin datasets. **It shows scores \n",
    "for a given test over time in different groups**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* We are querying the Group Meditation only for this exercise.\n",
    "* It shows Scores, the month (Time) and the person ID (subject)\n",
    "\n",
    "df = (pg.read_dataset('mixed_anova')\n",
    "    .query(\"Group == 'Meditation' and Time != 'January'\")\n",
    "    .drop(['Group'], axis=1)\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "We will change `time` to an integer that represents the \"month value\" and assign it to the `Month` column\n",
    "\n",
    "df['Month'] = df['Time'].replace({\"August\":8, \"June\":6})\n",
    "df.sort_values(by='Month', ascending=True, inplace=True)\n",
    "df.head()\n",
    "\n",
    "Let's check if the `Scores` are normally distributed across `Month` with `pg.normality()`\n",
    "* We see that levels for both months - 6 (June) and 8 (Aug) - are normally distributed\n",
    "\n",
    "pg.normality(data=df, dv='Scores', group='Month', alpha=0.05)\n",
    "\n",
    "We use `pg.pairwise_ttests()` to conduct a Paired Student t-test. Find the documentation [here](https://pingouin-stats.org/generated/pingouin.pairwise_ttests.html). The arguments used are: \n",
    "* ``data`` \n",
    "* ``dv`` for the dependent variable (scores)\n",
    "* ``within`` is the name of the column containing the within-subject factor (in this case, month)\n",
    "* ``subject`` as the subject identifier (like the person ID)\n",
    "\n",
    "We are interested in evaluating if the `Scores` levels are similar or different, considering the same group across `Month`\n",
    "\n",
    "pg.pairwise_ttests(data=df, dv='Scores', within='Month', subject='Subject')\n",
    "\n",
    "We are interested in p-value: `p-unc`\n",
    "\n",
    "pg.pairwise_ttests(data=df, dv='Scores', within='Month', subject='Subject', effsize='cohen').loc[0,'p-unc']\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We consider alpha = 0.05. \n",
    "* Since p-value (0.000143) is lower than the alpha, we reject the null hypothesis.\n",
    "* Therefore there is enough statistical difference between scores in June and August. Their levels are not the same!\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We use `pg.plot_paired()` to visualise this experiment. The function documentation is [here](https://pingouin-stats.org/generated/pingouin.plot_paired.html). The arguments are similar to the previous function (data, dv, within, subject), where dpi is the image quality we set at 150.\n",
    "* It shows a boxplot indicating the distribution levels of Scores for months 6 and 8. \n",
    "* You will notice red and green dots and lines \"travelling\" from one month to another. Each dot in this experiment is a person that, in Month 6, had a given score and, in Month 8, had another score.\n",
    "* If the line is red, the level decreases between months. If the line is green, the level increases. Have a look at the plot, and check visually if, in general, there are more greens or reds and if they are changing a lot or not.\n",
    "* The test assesses if the levels for the group as a whole increased or not.\n",
    "\n",
    "pg.plot_paired(data=df, dv='Scores', within='Month', subject='Subject', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  However, in more realistic applications you may have more \"Months\" to analyse. \n",
    "* For example, the previous experiment may have been conducted over more months\n",
    "\n",
    "\n",
    "\n",
    " Consider the same dataset in the previous example, but now we will consider three months\n",
    "* We will change time to an integer that represents the \"month value\" and assign it to the `Month` column\n",
    "\n",
    "df = (pg.read_dataset('mixed_anova')\n",
    "    .query(\"Group == 'Meditation'\")\n",
    "    .drop(['Group'], axis=1)\n",
    "    )\n",
    "\n",
    "df['Month'] = df['Time'].replace({\"January\":1, \"June\":6, \"August\":8})\n",
    "df.sort_values(by='Month', ascending=True, inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "Let's check if the `Scores` are normally distributed across `Month` with `pg.normality()`\n",
    "* The score in each month is normally distributed\n",
    "\n",
    "pg.normality(data=df, dv='Scores', group='Month', alpha=0.05)\n",
    "\n",
    "We use `pg.pairwise_ttests()` to conduct a pairwise Paired Student t-test. We are interested in evaluating if `Scores` levels are similar or different, considering the same group of people across `Month`\n",
    "* We will conduct three tests, each with a given pair of months. That is why it is called pairwise. We will be interested in column ``p-unc``\n",
    "* In the end we will know if there are different levels of scores, individually, from:\n",
    "  * January to June,\n",
    "  * June to August and \n",
    "  * January to August\n",
    "\n",
    "pg.pairwise_ttests(data=df, dv='Scores', within='Month', subject='Subject', effsize='cohen')\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We consider alpha = 0.05. \n",
    "\n",
    "* From January (Month 1) to June (Month 6), p-value (0.160902) is greater than the alpha; we accept the null hypothesis. Therefore there is **not** enough statistical difference between scores in **January and June.** Their levels are the same!\n",
    "\n",
    "* From June (Month 6) to August (Month 8), p-value (0.00014) is lower than the alpha; we reject the null hypothesis. Therefore there is enough statistical **difference between scores in June and August**. Their levels are not the same!\n",
    "\n",
    "* From January (Month 1) to August (Month 8), p-value (0.052379) is a bit greater than the alpha; we accept the null hypothesis. Therefore there is **not** enough statistical difference between scores in **January and August**. Their levels are the same!\n",
    "\n",
    "We use `pg.plot_paired()` to visualise this experiment\n",
    "* In the end, imagine the experiment was done using three different months. There was not enough statistical difference over time in the group when you compare Jan and Aug\n",
    "* However, visually there was an apparent increase from Jan to Jun, but that was not significant enough.\n",
    "* At the same time, if you compare the levels from Jun to Aug, there was a statistically significant decrease.\n",
    "\n",
    "pg.plot_paired(data=df, dv='Scores', within='Month', subject='Subject', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Analysis of Variance (ANOVA)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> An Analysis of Variance or ANOVA test is parametric that compares mean \"variation\" between three or more groups. The data should be normally distributed\n",
    "\n",
    "Consider a dataset from pingouin datasets. It shows `Pain threshold` levels across different people, `Hair color` (Dark Brunette, Light Blond, Dark Blond, Light Brunette). The subject is the person's ID\n",
    "\n",
    "df = pg.read_dataset('anova')\n",
    "print(df.shape)\n",
    "df.head(3)\n",
    "\n",
    "We can check `Pain threshold` normality across different `Hair color`. It is normally distributed\n",
    "\n",
    "pg.normality(df, dv='Pain threshold',group='Hair color', alpha=0.05)\n",
    "\n",
    "We combine a boxplot and swarm plot to visually check `Pain threshold` across different `Hair color`\n",
    "* **Visually speaking**, we notice few data points. And it looks like to have a `Pain threshold` difference across different `Hair color`. However, it is **wise** not to conclude anything before conducting a statistical test.\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.boxplot(data=df,x=\"Hair color\", y=\"Pain threshold\", ax=axes[0])\n",
    "sns.swarmplot(data=df,x=\"Hair color\", y=\"Pain threshold\", dodge=True, ax=axes[1])\n",
    "plt.show()\n",
    "\n",
    "We conduct an ANOVA test with `pg.anova()`. The function documentation is found [here](https://pingouin-stats.org/generated/pingouin.anova.html#pingouin.anova)\n",
    "\n",
    "  pg.anova(data=df, dv='Pain threshold', between='Hair color', detailed=True)\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in p-unc, which is 0.004114\t\n",
    "* We consider our significant level alpha = 0.05. \n",
    "* Since p-value (0.004114) is lower than the alpha, we reject the null hypothesis.\n",
    "\n",
    "* Therefore there is enough statistical difference to conclude that Pain threshold levels are different between different hair colour\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests - Unit 03: Nonparametric Statistical Tests\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "  * Conduct and interpret statistical tests using Mann Whitney, Wilcoxon and Kruskal Wallis test\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import pingouin as pg\n",
    "import scipy\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Statistical Tests - Unit 03: Nonparametric Statistical Tests\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> There are parametric and nonparametric statistical tests.\n",
    "* Depending on the normality of your data (meaning if it is a normal distribution or not), you may use a parametric test or a nonparametric test\n",
    "\n",
    "  * If it is normally distributed, we use a parametric test.\n",
    "  * If it is not, we use a nonparametric test.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **In this unit, we will cover nonparametric tests**\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Mann-Whitney U Test\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">   A Mann-Whitney U Test is a nonparametric test used to determine if there are differences between two groups where at least one group is not normally distributed.\n",
    "* The samples should be independent (or unpaired).\n",
    "* A nonparametric version of the independent t-test we saw in the previous unit.\n",
    "\n",
    "Let's consider a DataFrame that has Col1 and Col2 columns made with NumPy function to create not normal distributed data\n",
    "\n",
    "np.random.seed(1)\n",
    "df = pd.DataFrame(data={'Col1':np.random.uniform(low=0, high=1, size=500),\n",
    "                        \"Col2\":np.random.uniform(low=0.1, high=1, size=500)})\n",
    "df.head()\n",
    "\n",
    "We check for normality. Both are not normally distributed\n",
    "\n",
    "pg.normality(data=df, alpha=0.05)\n",
    "\n",
    "We plot both columns in a histogram and boxplot to better understand the levels\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1 ,ncols=2 ,figsize=(12,5))\n",
    "sns.histplot(data=df, kde=True, ax=axes[0])\n",
    "sns.boxplot(data=df, ax=axes[1])\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "We use `pg.mwu()` to conduct a  Mann-Whitney U Test. The documentation link is [here](https://pingouin-stats.org/generated/pingouin.mwu.html). The arguments we use are x and y, where we parse the numerical distribution\n",
    "\n",
    "pg.mwu(x=df['Col1'], y=df['Col2'])\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in p-val, which is 0.0784\n",
    "* We consider our significant level alpha = 0.05. \n",
    "* Since p-value (0.0784) is higher than the alpha, we accept the null hypothesis.\n",
    "\n",
    "* Therefore there is not enough statistical difference to conclude the levels are different.\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Wilcoxon Test\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  A Wilcoxon Test is a non-parametric test used when you'd like to use the paired t–test. At least one of the samples should not be **normally distributed**.\n",
    "* The samples should be **dependent (or paired)**\n",
    "  * It should be a sample of matched pairs. \n",
    "  * For example, **imagine the same group is tested twice**. Say you want to examine the difference between people's scores on a test before and after a training intervention \n",
    "\n",
    "\n",
    "\n",
    "Let's consider a DataFrame that has Col3 and Col4 columns made with a python list\n",
    "\n",
    "df = pd.DataFrame(data={'Col3':[18.3, 13.3, 16.5, 12.6, 9.5, 13.6, 8.1, 8.9, 10, 8.3, 7.9, 8.1, 13.4],\n",
    "                        \"Col4\":[12.7, 11.1, 15.3, 12.7, 10.5, 15.6, 11.2, 14.2, 16.3, 15.5, 19.9, 20.4, 36.8]\n",
    "                        })\n",
    "df.head()\n",
    "\n",
    "Let's check for normality. One is not normally distributed; we can use the Wilcoxon test\n",
    "\n",
    "pg.normality(data=df, alpha=0.05)\n",
    "\n",
    "We plot both columns in a histogram and boxplot to better understand the levels\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1 ,ncols=2 ,figsize=(12,5))\n",
    "sns.histplot(data=df, kde=True, ax=axes[0])\n",
    "sns.boxplot(data=df, ax=axes[1])\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "We use `pg.wilcoxon()` to conduct a Wilcoxon Test. The documentation is [here](https://pingouin-stats.org/generated/pingouin.wilcoxon.html). The arguments we use are x and y, as the numerical data we want to compare.\n",
    "\n",
    "pg.wilcoxon(x=df['Col3'], y=df['Col4'])\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in the p-val, which is 0.0397\n",
    "* We consider our significant level alpha = 0.05. \n",
    "* Since p-value (0.0397) is lower than the alpha, we reject the null hypothesis.\n",
    "\n",
    "* Therefore there is enough statistical difference to conclude the levels are different.\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Kruskal-Wallis\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A Kruskal-Wallis test is a nonparametric test used to determine if there are differences between three or more groups, considered when at least one of the distributions is not normally distributed\n",
    "* A nonparametric alternative to one-way ANOVA\n",
    "\n",
    "\n",
    "\n",
    "We use a pingouin dataset. We will be interested in Metric and Performance variables to demonstrate the concept in this exercise\n",
    "\n",
    "df= pg.read_dataset(\"rm_anova2\").filter(['Metric',\t'Performance'])\n",
    "df.head()\n",
    "\n",
    "We want to know the metric distribution levels, so we use `.value_counts()`. There are three levels (action, product and client)\n",
    "\n",
    "df['Metric'].value_counts()\n",
    "\n",
    "We check for normality. One is not; so we can use Kruskal Wallis\n",
    "\n",
    "pg.normality(data=df, dv='Performance', group='Metric', alpha=0.05)\n",
    "\n",
    "We combine a boxplot and swarm plot to visually check `Performance` across different `Metric`\n",
    "* **Visually**, we notice few data points. And it looks to have a `Performance` difference across different `Metric`. However, it is **wise** not to conclude anything before conducting a statistical test.\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.boxplot(data=df, x=\"Metric\", y=\"Performance\", ax=axes[0])\n",
    "sns.swarmplot(data=df, x=\"Metric\", y=\"Performance\", dodge=True, ax=axes[1])\n",
    "plt.show()\n",
    "\n",
    "We use `pg.kruskal()` to conduct a Kruskal Wallis test. The documentation is [here](https://pingouin-stats.org/generated/pingouin.kruskal.html#pingouin.kruskal). The arguments are data, ``dv`` as the dependent variable and ``between`` as the variable, which we will use to analyse the levels in between.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pg.kruskal(data=df, dv='Performance', between='Metric')\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested in p-unc, which is 0.00012\n",
    "* We consider our significant level alpha = 0.05. \n",
    "* Since p-value (0.00012) is lower than the alpha, we reject the null hypothesis.\n",
    "a\n",
    "* Therefore there is enough statistical difference to conclude the levels are different.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
